{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ju9xaF1L3gbs"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import html\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HT86T-_q3gbw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics=[(\"Artificial_Intelligence\",'https://www.outerplaces.com/tag?tag=Artificial_Intelligence&page='),(\"Sci-Fi_Movies\",\"https://www.outerplaces.com/tag?tag=Sci-Fi_Movies&page=\")]\n",
    "for topic in topics:\n",
    "    bout_going={}\n",
    "    count=1\n",
    "    paged = topic[1]\n",
    "    \n",
    "    for i in range(1,100):\n",
    "        page=paged+str(i)\n",
    "        spec_page=requests.get(page,headers=headers).text\n",
    "        soup = BeautifulSoup(spec_page, 'lxml')\n",
    "\n",
    "        [tagstring.extract() for tagstring in soup('script')] ### extracts all content not between balance <script> tags\n",
    "        [tagstring.extract() for tagstring in soup('table')] ### extracts all content not between balance <table> tags\n",
    "        [tagstring.extract() for tagstring in soup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "        [tagstring.extract() for tagstring in soup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "        [tagstring.extract() for tagstring in soup('ol')] ### extracts all content not between balance <ol> tags\n",
    "        [tagstring.extract() for tagstring in soup('ul')] ### extracts all content not between balance <ul> tags\n",
    "        [tagstring.extract() for tagstring in soup('h1')] ### extracts all content not between balance <h1> tags\n",
    "        [tagstring.extract() for tagstring in soup('h2')] ### extracts all content not between balance <h2> tags\n",
    "        [tagstring.extract() for tagstring in soup('h3')] ### extracts all content not between balance <h3> tags\n",
    "        [tagstring.extract() for tagstring in soup('h4')] ### extracts all content not between balance <h4> tags\n",
    "        [tagstring.extract() for tagstring in soup('h5')] ### extracts all content not between balance <h5> tags\n",
    "        [tagstring.extract() for tagstring in soup('img')] ### extracts all content not between balance <img> tags\n",
    "\n",
    "        filtered_content = soup.find_all('div', class_=\"tagged-article\")\n",
    "        #print(type(filtered_content))\n",
    "        content = \"\"\n",
    "        for stuff in filtered_content:\n",
    "            #content+= \"<<< \"+str(wrapped_paragraph.wrap)+\" >>>\"\n",
    "            info_need = str(stuff.find('a'))\n",
    "            url = re.search(r\"href=\\\"(.*?)\\\"\",info_need,re.DOTALL)[1]\n",
    "            title=re.search(r\"title=\\\"(.*?)\\\"\",info_need,re.DOTALL)[1]\n",
    "            bout_going[url] = {\"title\":title, \"description\":\"\",  \"keywords\":\"\",  \"content\":\"\"}\n",
    "            print(count,len(bout_going))\n",
    "            count+=1\n",
    "\n",
    "    count=1\n",
    "    for i in bout_going.keys():\n",
    "        spec_page=requests.get(i,headers=headers).text\n",
    "        soup = BeautifulSoup(spec_page, 'lxml') \n",
    "        [tagstring.extract() for tagstring in soup('script')] ### extracts all content not between balance <script> tags\n",
    "        [tagstring.extract() for tagstring in soup('table')] ### extracts all content not between balance <table> tags\n",
    "        [tagstring.extract() for tagstring in soup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "        [tagstring.extract() for tagstring in soup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "        [tagstring.extract() for tagstring in soup('ol')] ### extracts all content not between balance <ol> tags\n",
    "        [tagstring.extract() for tagstring in soup('ul')] ### extracts all content not between balance <ul> tags\n",
    "        [tagstring.extract() for tagstring in soup('h1')] ### extracts all content not between balance <h1> tags\n",
    "        [tagstring.extract() for tagstring in soup('h2')] ### extracts all content not between balance <h2> tags\n",
    "        [tagstring.extract() for tagstring in soup('h3')] ### extracts all content not between balance <h3> tags\n",
    "        [tagstring.extract() for tagstring in soup('h4')] ### extracts all content not between balance <h4> tags\n",
    "        [tagstring.extract() for tagstring in soup('h5')] ### extracts all content not between balance <h5> tags\n",
    "        [tagstring.extract() for tagstring in soup('img')] ### extracts all content not between balance <img> tags\n",
    "        [tagstring.extract() for tagstring in soup('br')] ### extracts all content not between balance <img> tags\n",
    "\n",
    "        filtered_content = soup.find_all('div', class_=\"main-article\")\n",
    "        content = \"\"\n",
    "        for wrapped_paragraph in filtered_content:\n",
    "            content+= str(wrapped_paragraph.wrap)+\" \"\n",
    "        content = re.sub(r\"\\s+\",\" \",content,re.DOTALL).strip()\n",
    "        bout_going[i][\"content\"]= content\n",
    "        keywords = [word.lower().strip() for word in re.findall(r\"<span\\sitemprop=\\\"keywords\\\">([^><]+?)</span>\",spec_page,re.DOTALL)]\n",
    "        bout_going[i][\"keywords\"]= keywords\n",
    "        descrip = re.search(r\"<meta\\sproperty=\\\"og:description\\\"\\scontent=\\\"(.*?)\\\"\",spec_page,re.DOTALL)\n",
    "        if descrip:\n",
    "            bout_going[i][\"description\"] = descrip[1]\n",
    "        print(count)\n",
    "        count+=1\n",
    "    with open(\"outerplaces.com_\"+  topic[0] +str(len(bout_going))+\".json\",\"w\") as file:\n",
    "        json.dump(bout_going,file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cvxWcdtc3gb1"
   },
   "source": [
    "# Horror Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kofgvzwk3gb1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics=[(\"Movies_Horror\",'https://www.pophorror.com/category/news/page/')]\n",
    "for topic in topics:\n",
    "    bout_going={}\n",
    "    count=1\n",
    "    paged = topic[1]\n",
    "    \n",
    "    for i in range(1,100):\n",
    "        page=paged+str(i)\n",
    "        spec_page=requests.get(page,headers=headers).text\n",
    "        soup = BeautifulSoup(spec_page, 'lxml')\n",
    "\n",
    "        [tagstring.extract() for tagstring in soup('script')] ### extracts all content not between balance <script> tags\n",
    "        [tagstring.extract() for tagstring in soup('table')] ### extracts all content not between balance <table> tags\n",
    "        [tagstring.extract() for tagstring in soup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "        [tagstring.extract() for tagstring in soup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "        [tagstring.extract() for tagstring in soup('ol')] ### extracts all content not between balance <ol> tags\n",
    "        [tagstring.extract() for tagstring in soup('ul')] ### extracts all content not between balance <ul> tags\n",
    "        [tagstring.extract() for tagstring in soup('h1')] ### extracts all content not between balance <h1> tags\n",
    "        [tagstring.extract() for tagstring in soup('h2')] ### extracts all content not between balance <h2> tags\n",
    "        [tagstring.extract() for tagstring in soup('h3')] ### extracts all content not between balance <h3> tags\n",
    "        [tagstring.extract() for tagstring in soup('h4')] ### extracts all content not between balance <h4> tags\n",
    "        [tagstring.extract() for tagstring in soup('h5')] ### extracts all content not between balance <h5> tags\n",
    "        [tagstring.extract() for tagstring in soup('img')] ### extracts all content not between balance <img> tags\n",
    "\n",
    "        filtered_content = soup.find_all('article', class_=\"item-list\")\n",
    "        content = \"\"\n",
    "        for stuff in filtered_content:\n",
    "            allit = str(stuff.wrap)\n",
    "            thesoup=BeautifulSoup(allit, 'lxml')\n",
    "            title = \"\"\n",
    "            #print(allit)\n",
    "            info_entry = stuff.find('div', class_=\"entry\")\n",
    "            description = info_entry.find('p').text\n",
    "            url = stuff.find('a', href=True)\n",
    "            url = re.search(r\"href=\\\"(.*?)\\\"\",str(url),re.DOTALL)[1]\n",
    "            bout_going[url] = {\"title\":title, \"description\":description,  \"keywords\":[],  \"content\":\"\"}\n",
    "            #print(json.dumps(bout_going[url],indent=3))\n",
    "            count+=1\n",
    "            print(count)\n",
    "\n",
    "    count=1\n",
    "    for i in bout_going.keys():\n",
    "        spec_page=requests.get(i,headers=headers).text\n",
    "        soup = BeautifulSoup(spec_page, 'lxml') \n",
    "        [tagstring.extract() for tagstring in soup('script')] ### extracts all content not between balance <script> tags\n",
    "        [tagstring.extract() for tagstring in soup('table')] ### extracts all content not between balance <table> tags\n",
    "        [tagstring.extract() for tagstring in soup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "        [tagstring.extract() for tagstring in soup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "        [tagstring.extract() for tagstring in soup('ol')] ### extracts all content not between balance <ol> tags\n",
    "        [tagstring.extract() for tagstring in soup('ul')] ### extracts all content not between balance <ul> tags\n",
    "        [tagstring.extract() for tagstring in soup('h1')] ### extracts all content not between balance <h1> tags\n",
    "        [tagstring.extract() for tagstring in soup('h2')] ### extracts all content not between balance <h2> tags\n",
    "        [tagstring.extract() for tagstring in soup('h3')] ### extracts all content not between balance <h3> tags\n",
    "        [tagstring.extract() for tagstring in soup('h4')] ### extracts all content not between balance <h4> tags\n",
    "        [tagstring.extract() for tagstring in soup('h5')] ### extracts all content not between balance <h5> tags\n",
    "        [tagstring.extract() for tagstring in soup('img')] ### extracts all content not between balance <img> tags\n",
    "        [tagstring.extract() for tagstring in soup('br')] ### extracts all content not between balance <img> tags\n",
    "\n",
    "        filtered_content = soup.find_all('div', class_=\"entry\")\n",
    "        content = \"\"\n",
    "        for wrapped_paragraph in filtered_content:\n",
    "            content+= str(wrapped_paragraph.wrap)+\" \"\n",
    "        content = re.sub(r\"\\s+\",\" \",content,re.DOTALL).strip()\n",
    "        print(content)\n",
    "        bout_going[i][\"content\"]= content.replace(\"<bound method PageElement.wrap of \",\"\").strip().replace(\">>\",\">\")\n",
    "        kws = re.search(r\"\\\"keywords\\\":\\\"(.*?)\\\"\",spec_page,re.DOTALL)\n",
    "        if kws:\n",
    "            keywords = [word.lower().strip() for word in kws[1]]\n",
    "            bout_going[i][\"keywords\"]= keywords\n",
    "        title= re.search(r\"<title>(.*?)</title>\",spec_page,re.DOTALL)\n",
    "        if title:\n",
    "            title = title[1].strip()\n",
    "        bout_going[i][\"content\"]\n",
    "            print(count)\n",
    "            count+=1\n",
    "        with open(\"pophorror.com_\"+  topic[0] +str(len(bout_going))+\".json\",\"w\") as file:\n",
    "            json.dump(bout_going,file)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGh5pxOc3gb4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aM8pnV8d3gb6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics=[(\"Short_Cartoon_Films\",\"https://www.cartoonbrew.com/shorts/page/\")]\n",
    "for topic in topics:\n",
    "    bout_going={}\n",
    "    count=1\n",
    "    paged = topic[1]\n",
    "    \n",
    "    for i in range(1,100):\n",
    "        page=paged+str(i)\n",
    "        spec_page=requests.get(page,headers=headers).text\n",
    "        soup = BeautifulSoup(spec_page, 'lxml')\n",
    "\n",
    "        [tagstring.extract() for tagstring in soup('script')] ### extracts all content not between balance <script> tags\n",
    "        [tagstring.extract() for tagstring in soup('table')] ### extracts all content not between balance <table> tags\n",
    "        [tagstring.extract() for tagstring in soup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "        [tagstring.extract() for tagstring in soup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "        [tagstring.extract() for tagstring in soup('ol')] ### extracts all content not between balance <ol> tags\n",
    "        [tagstring.extract() for tagstring in soup('ul')] ### extracts all content not between balance <ul> tags\n",
    "        #[tagstring.extract() for tagstring in soup('h1')] ### extracts all content not between balance <h1> tags\n",
    "        #[tagstring.extract() for tagstring in soup('h2')] ### extracts all content not between balance <h2> tags\n",
    "        [tagstring.extract() for tagstring in soup('h3')] ### extracts all content not between balance <h3> tags\n",
    "        [tagstring.extract() for tagstring in soup('h4')] ### extracts all content not between balance <h4> tags\n",
    "        [tagstring.extract() for tagstring in soup('h5')] ### extracts all content not between balance <h5> tags\n",
    "        [tagstring.extract() for tagstring in soup('img')] ### extracts all content not between balance <img> tags\n",
    "\n",
    "        filtered_content = soup.find_all('div', class_=\"cb-post-content\")\n",
    "        content = \"\"\n",
    "        for stuff in filtered_content:\n",
    "            title=stuff.find('h2',class_=\"entry-title\").text\n",
    "            description = stuff.find('div','entry-summary').text\n",
    "            url = stuff.find('a', href=True)\n",
    "            url = re.search(r\"href=\\\"(.*?)\\\"\",str(url),re.DOTALL)[1]\n",
    "            bout_going[url] = {\"title\":title, \"description\":description,  \"keywords\":[],  \"content\":\"\"}\n",
    " \n",
    "            print(i,count,len(bout_going))\n",
    "\n",
    "\n",
    "            spage=requests.get(url,headers=headers).text\n",
    "            newsoup = BeautifulSoup(spage, 'lxml') \n",
    "            [tagstring.extract() for tagstring in newsoup('script')] ### extracts all content not between balance <script> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('table')] ### extracts all content not between balance <table> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('ol')] ### extracts all content not between balance <ol> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('ul')] ### extracts all content not between balance <ul> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h1')] ### extracts all content not between balance <h1> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h2')] ### extracts all content not between balance <h2> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h3')] ### extracts all content not between balance <h3> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h4')] ### extracts all content not between balance <h4> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h5')] ### extracts all content not between balance <h5> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('img')] ### extracts all content not between balance <img> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('br')] ### extracts all content not between balance <img> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('figure')] ### extracts all content not between balance <img> tags\n",
    "\n",
    "\n",
    "            filtered_content = newsoup.find_all('div', class_=\"entry-content\")\n",
    "            content = \"\"\n",
    "            for wrapped_paragraph in filtered_content:\n",
    "                content+= str(wrapped_paragraph.wrap)+\" \"\n",
    "            content = re.sub(r\"\\s+\",\" \",content,re.DOTALL).strip()\n",
    "\n",
    "            #print(content)\n",
    "            bout_going[url][\"content\"]= content.replace('<div class=\"entry-content\">',\"\").strip().replace(\">>\",\">\")\n",
    "            kws = re.search(r\"\\\"keywords\\\":\\\"(.*?)\\\"\",spage,re.DOTALL)\n",
    "            if kws:\n",
    "                keywords = [word.lower().strip() for word in kws[1].split(\", \")]\n",
    "                bout_going[url][\"keywords\"]= keywords\n",
    "            count+=1\n",
    "    with open(\"cartoonbrew.com_\"+topic[0]+str(len(bout_going))+\".json\",\"w\") as file:\n",
    "        json.dump(bout_going,file)\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nSR7T_y03gb8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hvhPiubE3gb-"
   },
   "outputs": [],
   "source": [
    "topics=[(\"civil_engineering\",\"https://www.sciencedaily.com/news/matter_energy/civil_engineering/#page=\")]\n",
    "for topic in topics:\n",
    "    bout_going={}\n",
    "    count=1\n",
    "    paged = topic[1]\n",
    "    \n",
    "    for i in range(1,200):\n",
    "        page=paged+str(i)\n",
    "        spec_page=requests.get(page,headers=headers).text\n",
    "        soup = BeautifulSoup(spec_page, 'lxml')\n",
    "\n",
    "        [tagstring.extract() for tagstring in soup('script')] ### extracts all content not between balance <script> tags\n",
    "        [tagstring.extract() for tagstring in soup('table')] ### extracts all content not between balance <table> tags\n",
    "        [tagstring.extract() for tagstring in soup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "        [tagstring.extract() for tagstring in soup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "        [tagstring.extract() for tagstring in soup('ol')] ### extracts all content not between balance <ol> tags\n",
    "        [tagstring.extract() for tagstring in soup('ul')] ### extracts all content not between balance <ul> tags\n",
    "        #[tagstring.extract() for tagstring in soup('h1')] ### extracts all content not between balance <h1> tags\n",
    "        #[tagstring.extract() for tagstring in soup('h2')] ### extracts all content not between balance <h2> tags\n",
    "       # [tagstring.extract() for tagstring in soup('h3')] ### extracts all content not between balance <h3> tags\n",
    "        #[tagstring.extract() for tagstring in soup('h4')] ### extracts all content not between balance <h4> tags\n",
    "        [tagstring.extract() for tagstring in soup('h5')] ### extracts all content not between balance <h5> tags\n",
    "        [tagstring.extract() for tagstring in soup('img')] ### extracts all content not between balance <img> tags\n",
    "\n",
    "        filtered_content = soup.find_all('div', class_=\"tab-pane\")\n",
    "        for stuff in filtered_content:\n",
    "            try:\n",
    "                description=stuff.text\n",
    "                #print(description)\n",
    "                found=stuff.find('span',class_=\"more\")\n",
    "                title=stuff.find('h3').text\n",
    "                #print(title)\n",
    "                description = stuff.text\n",
    "                #print(description)\n",
    "                url = stuff.find('a', href=True)\n",
    "\n",
    "                url = \"https://www.sciencedaily.com\"+re.search(r\"href=\\\"(.*?)\\\"\",str(url),re.DOTALL)[1]\n",
    "                bout_going[url] = {\"title\":title, \"description\":description,  \"keywords\":[],  \"content\":\"\"}\n",
    "                #print(url)\n",
    "            except:\n",
    "                pass\n",
    "            spage=requests.get(url,headers=headers).text\n",
    "            newsoup = BeautifulSoup(spage, 'lxml') \n",
    "            [tagstring.extract() for tagstring in newsoup('script')] ### extracts all content not between balance <script> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('table')] ### extracts all content not between balance <table> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('ol')] ### extracts all content not between balance <ol> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('ul')] ### extracts all content not between balance <ul> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h1')] ### extracts all content not between balance <h1> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h2')] ### extracts all content not between balance <h2> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h3')] ### extracts all content not between balance <h3> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h4')] ### extracts all content not between balance <h4> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h5')] ### extracts all content not between balance <h5> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('img')] ### extracts all content not between balance <img> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('br')] ### extracts all content not between balance <img> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('figure')] ### extracts all content not between balance <img> tags\n",
    "\n",
    "\n",
    "            filtered_content = newsoup.find_all('div', class_=\"hyphenate less-top-margin\")\n",
    "            content = \"\"\n",
    "            for wrapped_paragraph in filtered_content:\n",
    "                content+= str(wrapped_paragraph.wrap)+\" \"\n",
    "            content = \" \".join(re.findall(r\"<p.*?>(.*?)</p>\",re.sub(r\"\\s+\",\" \",content,re.DOTALL).strip(),re.DOTALL))\n",
    "            bout_going[url][\"content\"]= content.replace('<div class=\"entry-content\">',\"\").strip().replace(\">>\",\">\")\n",
    "            kws = re.search(r\"<meta\\sname=\\\"keywords\\\"\\scontent=\\\"(.*?)\\\"\",spage,re.DOTALL)\n",
    "            if kws:\n",
    "                keywords = [word.lower().strip() for word in kws[1].split(\", \")]\n",
    "                bout_going[url][\"keywords\"]= list(set(keywords))\n",
    "            count+=1\n",
    "            print(len(bout_going))\n",
    "    with open(\"www.sciencedaily_\"+topic[0]+str(len(bout_going))+\".json\",\"w\") as file:\n",
    "        json.dump(bout_going,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FMV-kuAr3gcB"
   },
   "outputs": [],
   "source": [
    "len(bout_going)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ESzG1uvP3gcD"
   },
   "outputs": [],
   "source": [
    "topics=[(\"athleisure-sportwear\",\"https://www.whowhatwear.com/section/athleisure/page/\")]\n",
    "for topic in topics:\n",
    "    bout_going={}\n",
    "    count=1\n",
    "    paged = topic[1]\n",
    "    \n",
    "    for i in range(1,8):\n",
    "        page=paged+str(i)\n",
    "        spec_page=requests.get(page,headers=headers).text\n",
    "        soup = BeautifulSoup(spec_page, 'lxml')\n",
    "\n",
    "        [tagstring.extract() for tagstring in soup('script')] ### extracts all content not between balance <script> tags\n",
    "        [tagstring.extract() for tagstring in soup('table')] ### extracts all content not between balance <table> tags\n",
    "        [tagstring.extract() for tagstring in soup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "        [tagstring.extract() for tagstring in soup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "        [tagstring.extract() for tagstring in soup('ol')] ### extracts all content not between balance <ol> tags\n",
    "        [tagstring.extract() for tagstring in soup('ul')] ### extracts all content not between balance <ul> tags\n",
    "        #[tagstring.extract() for tagstring in soup('h1')] ### extracts all content not between balance <h1> tags\n",
    "        #[tagstring.extract() for tagstring in soup('h2')] ### extracts all content not between balance <h2> tags\n",
    "       # [tagstring.extract() for tagstring in soup('h3')] ### extracts all content not between balance <h3> tags\n",
    "        #[tagstring.extract() for tagstring in soup('h4')] ### extracts all content not between balance <h4> tags\n",
    "        [tagstring.extract() for tagstring in soup('h5')] ### extracts all content not between balance <h5> tags\n",
    "        [tagstring.extract() for tagstring in soup('img')] ### extracts all content not between balance <img> tags\n",
    "\n",
    "        filtered_content = soup.find_all('div', class_=\"card__item card__item--river card__item--river-channel\")\n",
    "        print(len(filtered_content))\n",
    "        #         if count == 1:\n",
    "#             print(filtered_content[0])\n",
    "        for stuff in filtered_content:\n",
    "            #print(str(stuff))\n",
    "            try:\n",
    "                url = stuff.find('a', href=True)\n",
    "                url = \"https://www.whowhatwear.com\"+re.search(r\"href=\\\"(.*?)\\\"\",str(url),re.DOTALL)[1]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            title=re.search(\"card__title\\scard__title--river\\scard__title--river-tag\\sitemprop=\\\"name\\\">([^<>]+?)</div>\",str(stuff),re.DOTALL)\n",
    "            if title:\n",
    "                title= title[1]\n",
    "            else:\n",
    "                title= \"\"\n",
    "\n",
    "            bout_going[url] = {\"title\":title, \"description\":\"\", \"keywords\":[],  \"content\":\"\"}\n",
    "\n",
    "            spage=requests.get(url,headers=headers).text\n",
    "            newsoup = BeautifulSoup(spage, 'lxml') \n",
    "            [tagstring.extract() for tagstring in newsoup('script')] ### extracts all content not between balance <script> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('table')] ### extracts all content not between balance <table> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('ol')] ### extracts all content not between balance <ol> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('ul')] ### extracts all content not between balance <ul> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h1')] ### extracts all content not between balance <h1> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h2')] ### extracts all content not between balance <h2> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h3')] ### extracts all content not between balance <h3> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h4')] ### extracts all content not between balance <h4> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h5')] ### extracts all content not between balance <h5> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('img')] ### extracts all content not between balance <img> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('br')] ### extracts all content not between balance <img> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('figure')] ### extracts all content not between balance <img> tags\n",
    "\n",
    "\n",
    "            filtered_content = newsoup.find_all('div', class_=\"text text__wrapper text__wrapper-default\")\n",
    "            content = \"\"\n",
    "            for wrapped_paragraph in filtered_content:\n",
    "                content+= str(wrapped_paragraph.wrap)+\" \"\n",
    "            content = html.unescape(\" \".join(re.findall(r\"<p.*?>(.*?)</p>\",re.sub(r\"\\s+\",\" \",content,re.DOTALL).strip(),re.DOTALL)))\n",
    "            bout_going[url][\"content\"]= content.replace('<div class=\"text text__wrapper text__wrapper-default\">',\"\").strip().replace(\">>\",\">\")\n",
    "            if bout_going[url][\"title\"] ==\"\":\n",
    "                title= re.search(r\"<meta\\sproperty=\\\"og:title\\\"\\scontent=\\\"(.*?)\\\"\",spage,re.DOTALL)\n",
    "                if title:\n",
    "                    title=title[1]\n",
    "                    bout_going[url][\"title\"]=html.unescape(title)\n",
    "            keywords = [html.unescape(word.lower().strip()) for word in re.findall(r\"<meta\\sproperty=\\\"article:tag\\\"\\scontent=\\\"(.*?)\\\"\",spage,re.DOTALL)]\n",
    "            bout_going[url][\"keywords\"]= list(set(keywords))\n",
    "            description = re.search(r\"meta\\sname=\\\"description\\\"\\scontent=\\\"(.*?)\\\"\",spage,re.DOTALL)\n",
    "            if description:\n",
    "                description = description[1]\n",
    "                bout_going[url][\"description\"]=html.unescape(description)\n",
    "            print(topic[0],i,len(bout_going))\n",
    "    with open(\"whowhatwear.com\"+topic[0]+str(len(bout_going))+\".json\",\"w\") as file:\n",
    "        json.dump(bout_going,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "akamUw7N3gcG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics=[(\"judaism\",\"https://religionnews.com/category/faith/judaism/page/\"),(\"sikhism\",\"https://religionnews.com/category/faith/sikhism/page/\"),(\"religion\",\"https://religionnews.com/category/news/page/\")]\n",
    "for topic in topics:\n",
    "    bout_going={}\n",
    "    remover=[]\n",
    "    count=1\n",
    "    paged = topic[1]\n",
    "    check_count_n1 = bout_going\n",
    "    for i in range(1,100):\n",
    "        page=paged+str(i)\n",
    "        spec_page= \" \".join(requests.get(page,headers=headers).text.split(\"\\n\"))\n",
    "        #print(spec_page)\n",
    "        soup = BeautifulSoup(spec_page, 'lxml')\n",
    "        [tagstring.extract() for tagstring in soup('a', class_=\"imageLinkWrapper\")]\n",
    "        [tagstring.extract() for tagstring in soup('script')] ### extracts all content not between balance <script> tags\n",
    "        [tagstring.extract() for tagstring in soup('table')] ### extracts all content not between balance <table> tags\n",
    "        [tagstring.extract() for tagstring in soup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "        [tagstring.extract() for tagstring in soup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "        [tagstring.extract() for tagstring in soup('ol')] ### extracts all content not between balance <ol> tags\n",
    "        [tagstring.extract() for tagstring in soup('ul')] ### extracts all content not between balance <ul> tags\n",
    "        #[tagstring.extract() for tagstring in soup('h1')] ### extracts all content not between balance <h1> tags\n",
    "        #[tagstring.extract() for tagstring in soup('h2')] ### extracts all content not between balance <h2> tags\n",
    "       # [tagstring.extract() for tagstring in soup('h3')] ### extracts all content not between balance <h3> tags\n",
    "        #[tagstring.extract() for tagstring in soup('h4')] ### extracts all content not between balance <h4> tags\n",
    "        [tagstring.extract() for tagstring in soup('h5')] ### extracts all content not between balance <h5> tags\n",
    "        [tagstring.extract() for tagstring in soup('img')] ### extracts all content not between balance <img> tags\n",
    "\n",
    "        filtered_content = soup.find_all('div', class_=\"entry-wrap\")\n",
    "        #print(len(filtered_content))\n",
    "\n",
    "        for stuff in filtered_content:\n",
    "            try:\n",
    "                url = stuff.find('a', href=True)\n",
    "                url = re.search(r\"href=\\\"(.*?)\\\"\",str(url),re.DOTALL)[1]\n",
    "            except:\n",
    "                continue            \n",
    "            \n",
    "            try:\n",
    "                title = stuff.find('h2').text.strip()\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            \n",
    "            description = stuff.find('div', class_=\"entry-content excerpt\").text.strip()\n",
    "\n",
    "            bout_going[url] = {\"title\":title, \"description\":description, \"keywords\":[],  \"content\":\"\"}\n",
    "            #print(bout_going[url])\n",
    "            spage=requests.get(url,headers=headers).text\n",
    "            newsoup = BeautifulSoup(spage, 'lxml') \n",
    "            [tagstring.extract() for tagstring in newsoup('script')] ### extracts all content not between balance <script> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('table')] ### extracts all content not between balance <table> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('ol')] ### extracts all content not between balance <ol> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('ul')] ### extracts all content not between balance <ul> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h1')] ### extracts all content not between balance <h1> tags\n",
    "           # [tagstring.extract() for tagstring in newsoup('h2')] ### extracts all content not between balance <h2> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h3')] ### extracts all content not between balance <h3> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h4')] ### extracts all content not between balance <h4> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h5')] ### extracts all content not between balance <h5> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('img')] ### extracts all content not between balance <img> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('br')] ### extracts all content not between balance <img> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('figure')] ### extracts all content not between balance <img> tags\n",
    "\n",
    "\n",
    "            filtered_content = newsoup.find_all('p')\n",
    "            content = \"\"\n",
    "            for wrapped_paragraph in filtered_content:\n",
    "                content+= str(wrapped_paragraph.wrap) +\" \"\n",
    "            \n",
    "            content = html.unescape(re.sub(r\"\\s+\",\" \",content,re.DOTALL).strip())\n",
    "            bout_going[url][\"content\"]= re.sub(\"<bound\\smethod.*?>>?\",\"\",\" \".join(content.split(\"\\n\")),re.DOTALL).replace(\">>\",\">\")\n",
    "            #print(content)\n",
    "            if len(content)<200:\n",
    "                remover.append(url)\n",
    "                continue\n",
    "            keywords = [word.lower().strip() for word in re.findall(r\"<meta\\sname=\\\"news_keywords\\\"\\scontent=\\\"(.*?)\\\"\",spec_page,re.DOTALL)]\n",
    "            if len(keywords)==0:\n",
    "                keys = re.search(r\"pageCategory\\\":\\[(.*?)\\]\",spage,re.DOTALL)\n",
    "                if keys:\n",
    "                    keywords = [word.lower().strip('\"').strip() for word in keys[1].split('\",\"')]\n",
    "            bout_going[url][\"keywords\"]= list(set(keywords))\n",
    "            print(topic[0],i,len(bout_going))\n",
    "        if len(bout_going)== len(check_count_n1):\n",
    "            continue\n",
    "            \n",
    "    for i in remover:\n",
    "        bout_going.pop(i)\n",
    "    with open(\"religionnews.com\"+topic[0]+str(len(bout_going))+\".json\",\"w\") as file:\n",
    "        json.dump(bout_going,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HjD_mZ3s3gcI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WelYQSfn3gcK"
   },
   "outputs": [],
   "source": [
    "topics=[(\"agnosticism\",\"https://www.worldreligionnews.com/religion-news/agnosticism/page/\"),(\"atheism\",\"https://www.worldreligionnews.com/religion-news/atheism/page/\"),(\"buddhism\",\"https://www.worldreligionnews.com/religion-news/buddhism/page/\"),(\"hinduism\",\"https://religionnews.com/category/faith/hinduism/page/\"),(\"christianity\",\"https://www.worldreligionnews.com/religion-news/christianity/page/\"),(\"judaism\",\"https://www.worldreligionnews.com/religion-news/judaism/page/\"),(\"sikhism\",\"https://www.worldreligionnews.com/religion-news/sikhism/page/\")]\n",
    "for topic in topics:\n",
    "    bout_going={}\n",
    "    remover=[]\n",
    "    count=1\n",
    "    paged = topic[1]\n",
    "    check_count_n1 = bout_going\n",
    "    for i in range(1,30):\n",
    "        page=paged+str(i)\n",
    "        spec_page= \" \".join(requests.get(page,headers=headers).text.split(\"\\n\"))\n",
    "        #print(spec_page)\n",
    "        soup = BeautifulSoup(spec_page, 'lxml')\n",
    "        [tagstring.extract() for tagstring in soup('a', class_=\"imageLinkWrapper\")]\n",
    "        [tagstring.extract() for tagstring in soup('script')] ### extracts all content not between balance <script> tags\n",
    "        [tagstring.extract() for tagstring in soup('table')] ### extracts all content not between balance <table> tags\n",
    "        [tagstring.extract() for tagstring in soup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "        [tagstring.extract() for tagstring in soup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "        [tagstring.extract() for tagstring in soup('ol')] ### extracts all content not between balance <ol> tags\n",
    "        [tagstring.extract() for tagstring in soup('ul')] ### extracts all content not between balance <ul> tags\n",
    "        #[tagstring.extract() for tagstring in soup('h1')] ### extracts all content not between balance <h1> tags\n",
    "        #[tagstring.extract() for tagstring in soup('h2')] ### extracts all content not between balance <h2> tags\n",
    "       # [tagstring.extract() for tagstring in soup('h3')] ### extracts all content not between balance <h3> tags\n",
    "        #[tagstring.extract() for tagstring in soup('h4')] ### extracts all content not between balance <h4> tags\n",
    "        [tagstring.extract() for tagstring in soup('h5')] ### extracts all content not between balance <h5> tags\n",
    "        [tagstring.extract() for tagstring in soup('img')] ### extracts all content not between balance <img> tags\n",
    "\n",
    "        filtered_content = soup.find_all('div', class_=\"post_inner_wrapper half\")\n",
    "        #print(len(filtered_content))\n",
    "\n",
    "        for stuff in filtered_content:\n",
    "            try:\n",
    "                url = stuff.find('a', href=True)\n",
    "                url = re.search(r\"href=\\\"(.*?)\\\"\",str(url),re.DOTALL)[1]\n",
    "            except:\n",
    "                continue            \n",
    "            \n",
    "            try:\n",
    "                title = stuff.find('h4').text.strip()\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            \n",
    "            description = \"\"\n",
    "\n",
    "            bout_going[url] = {\"title\":title, \"description\":description, \"keywords\":[],  \"content\":\"\"}\n",
    "            #print(bout_going[url])\n",
    "            spage=requests.get(url,headers=headers).text\n",
    "            newsoup = BeautifulSoup(spage, 'lxml') \n",
    "            [tagstring.extract() for tagstring in newsoup('span', class_='tweet_quote')]\n",
    "            [tagstring.extract() for tagstring in newsoup('style')] \n",
    "            [tagstring.extract() for tagstring in newsoup('script')] ### extracts all content not between balance <script> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('table')] ### extracts all content not between balance <table> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('ol')] ### extracts all content not between balance <ol> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('ul')] ### extracts all content not between balance <ul> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h1')] ### extracts all content not between balance <h1> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h2')] ### extracts all content not between balance <h2> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h3')] ### extracts all content not between balance <h3> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h4')] ### extracts all content not between balance <h4> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h5')] ### extracts all content not between balance <h5> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('img')] ### extracts all content not between balance <img> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('br')] ### extracts all content not between balance <img> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('figure')] ### extracts all content not between balance <img> tags\n",
    "            \n",
    "            \n",
    "            filtered_content = newsoup.find_all('p')\n",
    "            content = \"\"\n",
    "            for wrapped_paragraph in filtered_content:\n",
    "                content+= str(wrapped_paragraph.wrap) +\" \"\n",
    "            \n",
    "            content = html.unescape(re.sub(r\"\\s+\",\" \",content,re.DOTALL).strip())\n",
    "            bout_going[url][\"content\"]= re.sub(\"<bound\\smethod.*?>>?\",\"\",\" \".join(content.split(\"\\n\")),re.DOTALL).replace(\">>\",\">\")\n",
    "            #print(content)\n",
    "            if len(content)<200:\n",
    "                remover.append(url)\n",
    "                continue\n",
    "            keywords = [word.lower().strip() for word in re.findall(r\"<meta\\sproperty=\\\"article:tag\\\"\\scontent=\\\"(.*?)\\\"\",\" \".join(spec_page.split(\"\\n\")),re.DOTALL)]\n",
    "            if len(keywords)==0:\n",
    "                keys = re.findall(r\"<meta\\sproperty=\\\"article:tag\\\"\\scontent=\\\"(.*?)\\\"\",spage,re.DOTALL)\n",
    "                try:\n",
    "                    if keys:\n",
    "                        keys = keys[1].split('\",\"')\n",
    "                        keywords = [word.lower().strip('\"').strip() for word in keys]\n",
    "                except:\n",
    "                    pass\n",
    "            decrip = re.search(r\"<meta\\sproperty=\\\"og:description\\\"\\scontent=\\\"(.*?)\\\"\",content,re.DOTALL)\n",
    "            if decrip:\n",
    "                bout_going[url][\"description\"]=html.unescape(decrip[1].strip())\n",
    "            bout_going[url][\"keywords\"]= list(set(keywords))\n",
    "            print(topic[0],i,len(bout_going))\n",
    "        if len(bout_going)== len(check_count_n1) or len(bout_going)>500:\n",
    "            continue\n",
    "    \n",
    "    for i in remover:\n",
    "        bout_going.pop(i)\n",
    "    with open(\"worldreligionnews.com\"+topic[0]+str(len(bout_going))+\".json\",\"w\") as file:\n",
    "        json.dump(bout_going,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wSECLG-n3gcN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAWYiPgK3gcO"
   },
   "outputs": [],
   "source": [
    "\n",
    "topics=[(\"_retirement_\",\"https://www.wisebread.com/topic/personal-finance/retirement/more?page=\")]\n",
    "for topic in topics:\n",
    "    bout_going={}\n",
    "    remover=[]\n",
    "    count=1\n",
    "    paged = topic[1]\n",
    "    check_count_n1 = bout_going\n",
    "    for i in range(1,100):\n",
    "        page=paged+str(i)\n",
    "        spec_page= \" \".join(requests.get(page,headers=headers).text.split(\"\\n\"))\n",
    "        #print(spec_page)\n",
    "#         soup = BeautifulSoup(spec_page, 'lxml')\n",
    "#         [tagstring.extract() for tagstring in soup('a', class_=\"imageLinkWrapper\")]\n",
    "#         [tagstring.extract() for tagstring in soup('script')] ### extracts all content not between balance <script> tags\n",
    "#         [tagstring.extract() for tagstring in soup('table')] ### extracts all content not between balance <table> tags\n",
    "#         [tagstring.extract() for tagstring in soup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "#         [tagstring.extract() for tagstring in soup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "#         [tagstring.extract() for tagstring in soup('ol')] ### extracts all content not between balance <ol> tags\n",
    "#         [tagstring.extract() for tagstring in soup('ul')] ### extracts all content not between balance <ul> tags\n",
    "#         #[tagstring.extract() for tagstring in soup('h1')] ### extracts all content not between balance <h1> tags\n",
    "#         #[tagstring.extract() for tagstring in soup('h2')] ### extracts all content not between balance <h2> tags\n",
    "#        # [tagstring.extract() for tagstring in soup('h3')] ### extracts all content not between balance <h3> tags\n",
    "#         #[tagstring.extract() for tagstring in soup('h4')] ### extracts all content not between balance <h4> tags\n",
    "#         [tagstring.extract() for tagstring in soup('h5')] ### extracts all content not between balance <h5> tags\n",
    "#         [tagstring.extract() for tagstring in soup('img')] ### extracts all content not between balance <img> tags\n",
    "\n",
    "#         filtered_content = soup.find_all('div', class_=\"details\")\n",
    "#         #print(len(filtered_content))\n",
    "\n",
    "#         for stuff in filtered_content:\n",
    "# #             try:\n",
    "#             print(stuff.text)\n",
    "#             url = stuff.find('a', href=True)\n",
    "#             #print(url)\n",
    "# #             except:\n",
    "# #                 continue            \n",
    "            \n",
    "# #             try:\n",
    "#             title = stuff.find('h2').text.strip()\n",
    "#             #print(title)\n",
    "# #             except:\n",
    "# #                 continue\n",
    "        info =re.findall(\"<h2>.*?<a\\shref=\\\"(.*?)\\\"[^<>]+?>([^<>]+?)</a>.*?</h2>\",spec_page,re.DOTALL)\n",
    "    \n",
    "        for inf in info:\n",
    "            title=inf[1]\n",
    "            url = \"https://www.wisebread.com\"+inf[0]\n",
    "            description =\"\"\n",
    "            #print(url)\n",
    "            bout_going[url] = {\"title\":title, \"description\":description, \"keywords\":[],  \"content\":\"\"}\n",
    "            #print(bout_going[url])\n",
    "            spage=\" \".join(requests.get(url,headers=headers).text.split(\"\\n\"))\n",
    "            newsoup = BeautifulSoup(spage, 'lxml') \n",
    "#             [tagstring.extract() for tagstring in newsoup('span', class_='tweet_quote')]\n",
    "#             [tagstring.extract() for tagstring in newsoup('style')] \n",
    "#             [tagstring.extract() for tagstring in newsoup('script')] ### extracts all content not between balance <script> tags\n",
    "#             [tagstring.extract() for tagstring in newsoup('table')] ### extracts all content not between balance <table> tags\n",
    "#             [tagstring.extract() for tagstring in newsoup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "#             [tagstring.extract() for tagstring in newsoup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "#             [tagstring.extract() for tagstring in newsoup('ol')] ### extracts all content not between balance <ol> tags\n",
    "#             [tagstring.extract() for tagstring in newsoup('ul')] ### extracts all content not between balance <ul> tags\n",
    "#             [tagstring.extract() for tagstring in newsoup('h1')] ### extracts all content not between balance <h1> tags\n",
    "#             [tagstring.extract() for tagstring in newsoup('h2')] ### extracts all content not between balance <h2> tags\n",
    "#             [tagstring.extract() for tagstring in newsoup('h3')] ### extracts all content not between balance <h3> tags\n",
    "#             [tagstring.extract() for tagstring in newsoup('h4')] ### extracts all content not between balance <h4> tags\n",
    "#             [tagstring.extract() for tagstring in newsoup('h5')] ### extracts all content not between balance <h5> tags\n",
    "#             [tagstring.extract() for tagstring in newsoup('img')] ### extracts all content not between balance <img> tags\n",
    "#             [tagstring.extract() for tagstring in newsoup('br')] ### extracts all content not between balance <img> tags\n",
    "#             [tagstring.extract() for tagstring in newsoup('figure')] ### extracts all content not between balance <img> tags\n",
    "            \n",
    "            \n",
    "            filtered_content = newsoup.find_all('p')\n",
    "            content = \"\"\n",
    "            for wrapped_paragraph in filtered_content:\n",
    "                content+= str(wrapped_paragraph.wrap) +\" \"\n",
    "            \n",
    "            content = html.unescape(re.sub(r\"\\s+\",\" \",content,re.DOTALL).strip())\n",
    "            if len(content)<100:\n",
    "                remover.append(url)\n",
    "                continue\n",
    "#             content=\" \".join(re.sub(\"<bound\\smethod.*?>>?\",\"\",\" \".join(content.split(\"\\n\")),re.DOTALL).replace(\">>\",\">\").split(\"\\t\"))\n",
    "            bout_going[url][\"content\"]= content.replace(\"<bound method PageElement.wrap of <p>\",\"\").replace(\">>\",\">\")\n",
    "            #print(content,\"\\n\\n\\n\\n\")\n",
    "            if len(content)<200:\n",
    "                remover.append(url)\n",
    "                continue\n",
    "            keywords = [word.lower().strip() for word in re.findall(r\"<div\\sclass=\\\"terms\\\"[^<>]*?>.*?<a[^<>]*?>([^<>]*?)</a>[^<>]*?</div>\",\" \".join(spec_page.split(\"\\n\")),re.DOTALL)]\n",
    "            bout_going[url][\"keywords\"]= list(set(keywords))\n",
    "#             decrip = re.search(r\"<meta\\sproperty=\\\"og:description\\\"\\scontent=\\\"(.*?)\\\"\",content,re.DOTALL)\n",
    "#             if decrip:\n",
    "#                 bout_going[url][\"description\"]=html.unescape(decrip[1].strip())\n",
    "            print(topic[0],i,len(bout_going))\n",
    "        if len(bout_going)== len(check_count_n1):\n",
    "            continue\n",
    "    \n",
    "    for i in remover:\n",
    "        bout_going.pop(i)\n",
    "    with open(\"wisebread.com\"+topic[0]+str(len(bout_going))+\".json\",\"w\") as file:\n",
    "        json.dump(bout_going,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9B0A5FIO3gcQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwoImy3p3gcR",
    "outputId": "a690c0fe-4cc3-413a-c10c-6496e6528c1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_aviation_industry_ 1 1\n",
      "_aviation_industry_ 1 1\n",
      "_aviation_industry_ 1 1\n",
      "_aviation_industry_ 1 2\n",
      "_aviation_industry_ 1 3\n",
      "_aviation_industry_ 1 4\n",
      "_aviation_industry_ 1 4\n",
      "_aviation_industry_ 1 4\n",
      "_aviation_industry_ 1 5\n",
      "_aviation_industry_ 1 5\n",
      "_aviation_industry_ 1 5\n",
      "_aviation_industry_ 1 6\n",
      "_aviation_industry_ 1 6\n",
      "_aviation_industry_ 1 6\n",
      "_aviation_industry_ 1 7\n",
      "_aviation_industry_ 1 7\n",
      "_aviation_industry_ 1 7\n",
      "_aviation_industry_ 1 8\n",
      "_aviation_industry_ 1 8\n",
      "_aviation_industry_ 1 8\n",
      "_aviation_industry_ 1 9\n",
      "_aviation_industry_ 1 10\n",
      "_aviation_industry_ 1 11\n",
      "_aviation_industry_ 1 12\n",
      "_aviation_industry_ 1 13\n",
      "_aviation_industry_ 1 14\n",
      "_aviation_industry_ 1 14\n",
      "_aviation_industry_ 1 14\n",
      "_aviation_industry_ 1 15\n",
      "_aviation_industry_ 1 15\n",
      "_aviation_industry_ 1 15\n",
      "_aviation_industry_ 1 16\n",
      "_aviation_industry_ 1 17\n",
      "_aviation_industry_ 1 18\n",
      "_aviation_industry_ 1 18\n",
      "_aviation_industry_ 1 18\n",
      "_aviation_industry_ 1 19\n",
      "_aviation_industry_ 1 19\n",
      "_aviation_industry_ 1 19\n",
      "_aviation_industry_ 1 20\n",
      "_aviation_industry_ 1 20\n",
      "_aviation_industry_ 1 20\n",
      "_aviation_industry_ 1 21\n",
      "_aviation_industry_ 1 21\n",
      "_aviation_industry_ 1 21\n",
      "_aviation_industry_ 1 22\n",
      "_aviation_industry_ 1 23\n",
      "_aviation_industry_ 1 23\n",
      "_aviation_industry_ 1 23\n",
      "_aviation_industry_ 1 24\n",
      "_aviation_industry_ 1 24\n",
      "_aviation_industry_ 1 24\n",
      "_aviation_industry_ 1 25\n",
      "_aviation_industry_ 1 26\n",
      "_aviation_industry_ 1 26\n",
      "_aviation_industry_ 1 26\n",
      "_aviation_industry_ 1 27\n",
      "_aviation_industry_ 1 27\n",
      "_aviation_industry_ 1 27\n",
      "_aviation_industry_ 1 28\n",
      "_aviation_industry_ 1 28\n",
      "_aviation_industry_ 1 28\n",
      "_aviation_industry_ 1 29\n",
      "_aviation_industry_ 1 30\n",
      "_aviation_industry_ 1 31\n",
      "_aviation_industry_ 1 32\n",
      "_aviation_industry_ 1 32\n",
      "_aviation_industry_ 1 32\n",
      "_aviation_industry_ 1 33\n",
      "_aviation_industry_ 1 33\n",
      "_aviation_industry_ 1 33\n",
      "_aviation_industry_ 1 34\n",
      "_aviation_industry_ 1 35\n",
      "_aviation_industry_ 1 36\n",
      "_aviation_industry_ 1 37\n",
      "_aviation_industry_ 1 38\n",
      "_aviation_industry_ 1 38\n",
      "_aviation_industry_ 1 38\n",
      "_aviation_industry_ 1 39\n",
      "_aviation_industry_ 1 40\n",
      "_aviation_industry_ 1 40\n",
      "_aviation_industry_ 1 40\n",
      "_aviation_industry_ 1 41\n",
      "_aviation_industry_ 1 41\n",
      "_aviation_industry_ 1 41\n",
      "_aviation_industry_ 1 42\n",
      "_aviation_industry_ 1 42\n",
      "_aviation_industry_ 1 42\n",
      "_aviation_industry_ 1 43\n",
      "_aviation_industry_ 1 44\n",
      "_aviation_industry_ 1 45\n",
      "_aviation_industry_ 1 46\n",
      "_aviation_industry_ 1 47\n",
      "_aviation_industry_ 1 47\n",
      "_aviation_industry_ 1 47\n",
      "_aviation_industry_ 1 48\n",
      "_aviation_industry_ 1 48\n",
      "_aviation_industry_ 1 48\n",
      "_aviation_industry_ 1 49\n",
      "_aviation_industry_ 1 50\n",
      "_aviation_industry_ 1 51\n",
      "_aviation_industry_ 1 51\n",
      "_aviation_industry_ 1 51\n",
      "_aviation_industry_ 1 52\n",
      "_aviation_industry_ 1 52\n",
      "_aviation_industry_ 1 52\n",
      "_aviation_industry_ 1 53\n",
      "_aviation_industry_ 1 54\n",
      "_aviation_industry_ 1 54\n",
      "_aviation_industry_ 1 54\n",
      "_aviation_industry_ 1 55\n",
      "_aviation_industry_ 1 55\n",
      "_aviation_industry_ 1 55\n",
      "_aviation_industry_ 1 56\n",
      "_aviation_industry_ 1 56\n",
      "_aviation_industry_ 1 56\n",
      "_aviation_industry_ 1 57\n",
      "_aviation_industry_ 1 57\n",
      "_aviation_industry_ 1 57\n",
      "_aviation_industry_ 1 58\n",
      "_aviation_industry_ 1 58\n",
      "_aviation_industry_ 1 58\n",
      "_aviation_industry_ 1 59\n",
      "_aviation_industry_ 1 60\n",
      "_aviation_industry_ 1 61\n",
      "_aviation_industry_ 1 62\n",
      "_aviation_industry_ 1 63\n",
      "_aviation_industry_ 1 64\n",
      "_aviation_industry_ 1 64\n",
      "_aviation_industry_ 1 64\n",
      "_aviation_industry_ 1 65\n",
      "_aviation_industry_ 1 65\n",
      "_aviation_industry_ 1 65\n",
      "_aviation_industry_ 1 66\n",
      "_aviation_industry_ 1 66\n",
      "_aviation_industry_ 1 66\n",
      "_aviation_industry_ 1 67\n",
      "_aviation_industry_ 1 67\n",
      "_aviation_industry_ 1 67\n",
      "_aviation_industry_ 1 68\n",
      "_aviation_industry_ 1 68\n",
      "_aviation_industry_ 1 68\n",
      "_aviation_industry_ 1 69\n",
      "_aviation_industry_ 1 69\n",
      "_aviation_industry_ 1 69\n",
      "_aviation_industry_ 1 70\n",
      "_aviation_industry_ 1 70\n",
      "_aviation_industry_ 1 70\n",
      "_aviation_industry_ 1 71\n",
      "_aviation_industry_ 1 71\n",
      "_aviation_industry_ 1 71\n",
      "_aviation_industry_ 1 72\n",
      "_aviation_industry_ 1 72\n",
      "_aviation_industry_ 1 72\n",
      "_aviation_industry_ 1 73\n",
      "_aviation_industry_ 1 73\n",
      "_aviation_industry_ 1 73\n",
      "_aviation_industry_ 1 74\n",
      "_aviation_industry_ 1 74\n",
      "_aviation_industry_ 1 74\n",
      "_aviation_industry_ 1 75\n",
      "_aviation_industry_ 1 75\n",
      "_aviation_industry_ 1 75\n",
      "_aviation_industry_ 1 76\n",
      "_aviation_industry_ 1 76\n",
      "_aviation_industry_ 1 76\n",
      "_aviation_industry_ 1 77\n",
      "_aviation_industry_ 1 77\n",
      "_aviation_industry_ 1 77\n",
      "_aviation_industry_ 1 78\n",
      "_aviation_industry_ 1 78\n",
      "_aviation_industry_ 1 78\n",
      "_aviation_industry_ 1 79\n",
      "_aviation_industry_ 1 79\n",
      "_aviation_industry_ 1 79\n",
      "_aviation_industry_ 1 80\n",
      "_aviation_industry_ 1 80\n",
      "_aviation_industry_ 1 80\n",
      "_aviation_industry_ 1 81\n",
      "_aviation_industry_ 1 81\n",
      "_aviation_industry_ 1 81\n",
      "_aviation_industry_ 1 82\n",
      "_aviation_industry_ 1 82\n",
      "_aviation_industry_ 1 82\n",
      "_aviation_industry_ 1 83\n",
      "_aviation_industry_ 1 83\n",
      "_aviation_industry_ 1 83\n",
      "_aviation_industry_ 1 84\n",
      "_aviation_industry_ 1 85\n",
      "_aviation_industry_ 1 86\n",
      "_aviation_industry_ 1 87\n",
      "_aviation_industry_ 1 87\n",
      "_aviation_industry_ 1 87\n",
      "_aviation_industry_ 1 88\n",
      "_aviation_industry_ 1 89\n",
      "_aviation_industry_ 1 90\n",
      "_aviation_industry_ 1 91\n",
      "_aviation_industry_ 1 92\n",
      "_aviation_industry_ 1 93\n",
      "_aviation_industry_ 1 94\n",
      "_aviation_industry_ 1 94\n",
      "_aviation_industry_ 1 94\n",
      "_aviation_industry_ 1 95\n",
      "_aviation_industry_ 1 95\n",
      "_aviation_industry_ 1 95\n",
      "_aviation_industry_ 1 96\n",
      "_aviation_industry_ 1 96\n",
      "_aviation_industry_ 1 96\n",
      "_aviation_industry_ 1 97\n",
      "_aviation_industry_ 1 97\n",
      "_aviation_industry_ 1 97\n",
      "_aviation_industry_ 1 98\n",
      "_aviation_industry_ 1 99\n",
      "_aviation_industry_ 1 99\n",
      "_aviation_industry_ 1 99\n",
      "_aviation_industry_ 1 100\n",
      "_aviation_industry_ 2 101\n",
      "_aviation_industry_ 2 101\n",
      "_aviation_industry_ 2 101\n",
      "_aviation_industry_ 2 102\n",
      "_aviation_industry_ 2 103\n",
      "_aviation_industry_ 2 104\n",
      "_aviation_industry_ 2 104\n",
      "_aviation_industry_ 2 104\n",
      "_aviation_industry_ 2 105\n",
      "_aviation_industry_ 2 105\n",
      "_aviation_industry_ 2 105\n",
      "_aviation_industry_ 2 106\n",
      "_aviation_industry_ 2 106\n",
      "_aviation_industry_ 2 106\n",
      "_aviation_industry_ 2 107\n",
      "_aviation_industry_ 2 107\n",
      "_aviation_industry_ 2 107\n",
      "_aviation_industry_ 2 108\n",
      "_aviation_industry_ 2 108\n",
      "_aviation_industry_ 2 108\n",
      "_aviation_industry_ 2 109\n",
      "_aviation_industry_ 2 109\n",
      "_aviation_industry_ 2 109\n",
      "_aviation_industry_ 2 110\n",
      "_aviation_industry_ 2 111\n",
      "_aviation_industry_ 2 112\n",
      "_aviation_industry_ 2 112\n",
      "_aviation_industry_ 2 112\n",
      "_aviation_industry_ 2 113\n",
      "_aviation_industry_ 2 113\n",
      "_aviation_industry_ 2 113\n",
      "_aviation_industry_ 2 114\n",
      "_aviation_industry_ 2 114\n",
      "_aviation_industry_ 2 114\n",
      "_aviation_industry_ 2 115\n",
      "_aviation_industry_ 2 115\n",
      "_aviation_industry_ 2 115\n",
      "_aviation_industry_ 2 116\n",
      "_aviation_industry_ 2 116\n",
      "_aviation_industry_ 2 116\n",
      "_aviation_industry_ 2 117\n",
      "_aviation_industry_ 2 118\n",
      "_aviation_industry_ 2 119\n",
      "_aviation_industry_ 2 119\n",
      "_aviation_industry_ 2 119\n",
      "_aviation_industry_ 2 120\n",
      "_aviation_industry_ 2 121\n",
      "_aviation_industry_ 2 122\n",
      "_aviation_industry_ 2 122\n",
      "_aviation_industry_ 2 122\n",
      "_aviation_industry_ 2 123\n",
      "_aviation_industry_ 2 123\n",
      "_aviation_industry_ 2 123\n",
      "_aviation_industry_ 2 124\n",
      "_aviation_industry_ 2 124\n",
      "_aviation_industry_ 2 124\n",
      "_aviation_industry_ 2 125\n",
      "_aviation_industry_ 2 125\n",
      "_aviation_industry_ 2 125\n",
      "_aviation_industry_ 2 126\n",
      "_aviation_industry_ 2 127\n",
      "_aviation_industry_ 2 128\n",
      "_aviation_industry_ 2 128\n",
      "_aviation_industry_ 2 128\n",
      "_aviation_industry_ 2 129\n",
      "_aviation_industry_ 2 129\n",
      "_aviation_industry_ 2 129\n",
      "_aviation_industry_ 2 130\n",
      "_aviation_industry_ 2 131\n",
      "_aviation_industry_ 2 132\n",
      "_aviation_industry_ 2 132\n",
      "_aviation_industry_ 2 132\n",
      "_aviation_industry_ 2 133\n",
      "_aviation_industry_ 2 133\n",
      "_aviation_industry_ 2 133\n",
      "_aviation_industry_ 2 134\n",
      "_aviation_industry_ 2 134\n",
      "_aviation_industry_ 2 134\n",
      "_aviation_industry_ 2 135\n",
      "_aviation_industry_ 2 135\n",
      "_aviation_industry_ 2 135\n",
      "_aviation_industry_ 2 136\n",
      "_aviation_industry_ 2 136\n",
      "_aviation_industry_ 2 136\n",
      "_aviation_industry_ 2 137\n",
      "_aviation_industry_ 2 138\n",
      "_aviation_industry_ 2 139\n",
      "_aviation_industry_ 2 140\n",
      "_aviation_industry_ 2 140\n",
      "_aviation_industry_ 2 140\n",
      "_aviation_industry_ 2 141\n",
      "_aviation_industry_ 2 141\n",
      "_aviation_industry_ 2 141\n",
      "_aviation_industry_ 2 142\n",
      "_aviation_industry_ 2 142\n",
      "_aviation_industry_ 2 142\n",
      "_aviation_industry_ 2 143\n",
      "_aviation_industry_ 2 143\n",
      "_aviation_industry_ 2 143\n",
      "_aviation_industry_ 2 144\n",
      "_aviation_industry_ 2 145\n",
      "_aviation_industry_ 2 146\n",
      "_aviation_industry_ 2 147\n",
      "_aviation_industry_ 2 147\n",
      "_aviation_industry_ 2 147\n",
      "_aviation_industry_ 2 148\n",
      "_aviation_industry_ 2 149\n",
      "_aviation_industry_ 2 150\n",
      "_aviation_industry_ 2 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_aviation_industry_ 2 150\n",
      "_aviation_industry_ 2 151\n",
      "_aviation_industry_ 2 151\n",
      "_aviation_industry_ 2 151\n",
      "_aviation_industry_ 2 152\n",
      "_aviation_industry_ 2 152\n",
      "_aviation_industry_ 2 152\n",
      "_aviation_industry_ 2 153\n",
      "_aviation_industry_ 2 153\n",
      "_aviation_industry_ 2 153\n",
      "_aviation_industry_ 2 154\n",
      "_aviation_industry_ 2 154\n",
      "_aviation_industry_ 2 154\n",
      "_aviation_industry_ 2 155\n",
      "_aviation_industry_ 2 155\n",
      "_aviation_industry_ 2 155\n",
      "_aviation_industry_ 2 156\n",
      "_aviation_industry_ 2 156\n",
      "_aviation_industry_ 2 156\n",
      "_aviation_industry_ 2 157\n",
      "_aviation_industry_ 2 157\n",
      "_aviation_industry_ 2 157\n",
      "_aviation_industry_ 2 158\n",
      "_aviation_industry_ 2 158\n",
      "_aviation_industry_ 2 158\n",
      "_aviation_industry_ 2 159\n",
      "_aviation_industry_ 2 160\n",
      "_aviation_industry_ 2 160\n",
      "_aviation_industry_ 2 160\n",
      "_aviation_industry_ 2 161\n",
      "_aviation_industry_ 2 161\n",
      "_aviation_industry_ 2 161\n",
      "_aviation_industry_ 2 162\n",
      "_aviation_industry_ 2 162\n",
      "_aviation_industry_ 2 162\n",
      "_aviation_industry_ 2 163\n",
      "_aviation_industry_ 2 163\n",
      "_aviation_industry_ 2 163\n",
      "_aviation_industry_ 2 164\n",
      "_aviation_industry_ 2 165\n",
      "_aviation_industry_ 2 165\n",
      "_aviation_industry_ 2 165\n",
      "_aviation_industry_ 2 166\n",
      "_aviation_industry_ 2 166\n",
      "_aviation_industry_ 2 166\n",
      "_aviation_industry_ 2 167\n",
      "_aviation_industry_ 2 167\n",
      "_aviation_industry_ 2 167\n",
      "_aviation_industry_ 2 168\n",
      "_aviation_industry_ 2 169\n",
      "_aviation_industry_ 2 170\n",
      "_aviation_industry_ 2 170\n",
      "_aviation_industry_ 2 170\n",
      "_aviation_industry_ 2 171\n",
      "_aviation_industry_ 2 172\n",
      "_aviation_industry_ 2 172\n",
      "_aviation_industry_ 2 172\n",
      "_aviation_industry_ 2 173\n",
      "_aviation_industry_ 2 174\n",
      "_aviation_industry_ 2 175\n",
      "_aviation_industry_ 2 175\n",
      "_aviation_industry_ 2 175\n",
      "_aviation_industry_ 2 176\n",
      "_aviation_industry_ 2 177\n",
      "_aviation_industry_ 2 178\n",
      "_aviation_industry_ 2 179\n",
      "_aviation_industry_ 2 180\n",
      "_aviation_industry_ 2 180\n",
      "_aviation_industry_ 2 180\n",
      "_aviation_industry_ 2 181\n",
      "_aviation_industry_ 2 182\n",
      "_aviation_industry_ 2 182\n",
      "_aviation_industry_ 2 182\n",
      "_aviation_industry_ 2 183\n",
      "_aviation_industry_ 2 183\n",
      "_aviation_industry_ 2 183\n",
      "_aviation_industry_ 2 184\n",
      "_aviation_industry_ 2 184\n",
      "_aviation_industry_ 2 184\n",
      "_aviation_industry_ 2 185\n",
      "_aviation_industry_ 2 185\n",
      "_aviation_industry_ 2 185\n",
      "_aviation_industry_ 2 186\n",
      "_aviation_industry_ 2 186\n",
      "_aviation_industry_ 2 186\n",
      "_aviation_industry_ 2 187\n",
      "_aviation_industry_ 2 188\n",
      "_aviation_industry_ 2 188\n",
      "_aviation_industry_ 2 188\n",
      "_aviation_industry_ 2 189\n",
      "_aviation_industry_ 2 189\n",
      "_aviation_industry_ 2 189\n",
      "_aviation_industry_ 2 190\n",
      "_aviation_industry_ 2 191\n",
      "_aviation_industry_ 2 192\n",
      "_aviation_industry_ 2 192\n",
      "_aviation_industry_ 2 192\n",
      "_aviation_industry_ 2 193\n",
      "_aviation_industry_ 2 193\n",
      "_aviation_industry_ 2 193\n",
      "_aviation_industry_ 2 194\n",
      "_aviation_industry_ 2 194\n",
      "_aviation_industry_ 2 194\n",
      "_aviation_industry_ 2 195\n",
      "_aviation_industry_ 2 195\n",
      "_aviation_industry_ 2 195\n",
      "_aviation_industry_ 2 196\n",
      "_aviation_industry_ 2 197\n",
      "_aviation_industry_ 2 198\n",
      "_aviation_industry_ 2 199\n",
      "_aviation_industry_ 2 200\n",
      "_aviation_industry_ 2 200\n",
      "_aviation_industry_ 2 200\n",
      "_aviation_industry_ 3 201\n",
      "_aviation_industry_ 3 202\n",
      "_aviation_industry_ 3 202\n",
      "_aviation_industry_ 3 202\n",
      "_aviation_industry_ 3 203\n",
      "_aviation_industry_ 3 203\n",
      "_aviation_industry_ 3 203\n",
      "_aviation_industry_ 3 204\n",
      "_aviation_industry_ 3 204\n",
      "_aviation_industry_ 3 204\n",
      "_aviation_industry_ 3 205\n",
      "_aviation_industry_ 3 206\n",
      "_aviation_industry_ 3 206\n",
      "_aviation_industry_ 3 206\n",
      "_aviation_industry_ 3 207\n",
      "_aviation_industry_ 3 207\n",
      "_aviation_industry_ 3 207\n",
      "_aviation_industry_ 3 208\n",
      "_aviation_industry_ 3 208\n",
      "_aviation_industry_ 3 208\n",
      "_aviation_industry_ 3 209\n",
      "_aviation_industry_ 3 209\n",
      "_aviation_industry_ 3 209\n",
      "_aviation_industry_ 3 210\n",
      "_aviation_industry_ 3 211\n",
      "_aviation_industry_ 3 211\n",
      "_aviation_industry_ 3 211\n",
      "_aviation_industry_ 3 212\n",
      "_aviation_industry_ 3 212\n",
      "_aviation_industry_ 3 212\n",
      "_aviation_industry_ 3 213\n",
      "_aviation_industry_ 3 214\n",
      "_aviation_industry_ 3 214\n",
      "_aviation_industry_ 3 214\n",
      "_aviation_industry_ 3 215\n",
      "_aviation_industry_ 3 215\n",
      "_aviation_industry_ 3 215\n",
      "_aviation_industry_ 3 216\n",
      "_aviation_industry_ 3 216\n",
      "_aviation_industry_ 3 216\n",
      "_aviation_industry_ 3 217\n",
      "_aviation_industry_ 3 218\n",
      "_aviation_industry_ 3 218\n",
      "_aviation_industry_ 3 218\n",
      "_aviation_industry_ 3 219\n",
      "_aviation_industry_ 3 219\n",
      "_aviation_industry_ 3 219\n",
      "_aviation_industry_ 3 220\n",
      "_aviation_industry_ 3 220\n",
      "_aviation_industry_ 3 220\n",
      "_aviation_industry_ 3 221\n",
      "_aviation_industry_ 3 221\n",
      "_aviation_industry_ 3 221\n",
      "_aviation_industry_ 3 222\n",
      "_aviation_industry_ 3 223\n",
      "_aviation_industry_ 3 223\n",
      "_aviation_industry_ 3 223\n",
      "_aviation_industry_ 3 224\n",
      "_aviation_industry_ 3 224\n",
      "_aviation_industry_ 3 224\n",
      "_aviation_industry_ 3 225\n",
      "_aviation_industry_ 3 225\n",
      "_aviation_industry_ 3 225\n",
      "_aviation_industry_ 3 226\n",
      "_aviation_industry_ 3 226\n",
      "_aviation_industry_ 3 226\n",
      "_aviation_industry_ 3 227\n",
      "_aviation_industry_ 3 227\n",
      "_aviation_industry_ 3 227\n",
      "_aviation_industry_ 3 228\n",
      "_aviation_industry_ 3 228\n",
      "_aviation_industry_ 3 228\n",
      "_aviation_industry_ 3 229\n",
      "_aviation_industry_ 3 229\n",
      "_aviation_industry_ 3 229\n",
      "_aviation_industry_ 3 230\n",
      "_aviation_industry_ 3 230\n",
      "_aviation_industry_ 3 230\n",
      "_aviation_industry_ 3 231\n",
      "_aviation_industry_ 3 232\n",
      "_aviation_industry_ 3 232\n",
      "_aviation_industry_ 3 232\n",
      "_aviation_industry_ 3 233\n",
      "_aviation_industry_ 3 234\n",
      "_aviation_industry_ 3 234\n",
      "_aviation_industry_ 3 234\n",
      "_aviation_industry_ 3 235\n",
      "_aviation_industry_ 3 235\n",
      "_aviation_industry_ 3 235\n",
      "_aviation_industry_ 3 236\n",
      "_aviation_industry_ 3 236\n",
      "_aviation_industry_ 3 236\n",
      "_aviation_industry_ 3 237\n",
      "_aviation_industry_ 3 238\n",
      "_aviation_industry_ 3 239\n",
      "_aviation_industry_ 3 240\n",
      "_aviation_industry_ 3 241\n",
      "_aviation_industry_ 3 241\n",
      "_aviation_industry_ 3 241\n",
      "_aviation_industry_ 3 242\n",
      "_aviation_industry_ 3 242\n",
      "_aviation_industry_ 3 242\n",
      "_aviation_industry_ 3 243\n",
      "_aviation_industry_ 3 243\n",
      "_aviation_industry_ 3 243\n",
      "_aviation_industry_ 3 244\n",
      "_aviation_industry_ 3 244\n",
      "_aviation_industry_ 3 244\n",
      "_aviation_industry_ 3 245\n",
      "_aviation_industry_ 3 245\n",
      "_aviation_industry_ 3 245\n",
      "_aviation_industry_ 3 246\n",
      "_aviation_industry_ 3 246\n",
      "_aviation_industry_ 3 246\n",
      "_aviation_industry_ 3 247\n",
      "_aviation_industry_ 3 247\n",
      "_aviation_industry_ 3 247\n",
      "_aviation_industry_ 3 248\n",
      "_aviation_industry_ 3 248\n",
      "_aviation_industry_ 3 248\n",
      "_aviation_industry_ 3 249\n",
      "_aviation_industry_ 3 250\n",
      "_aviation_industry_ 3 251\n",
      "_aviation_industry_ 3 252\n",
      "_aviation_industry_ 3 252\n",
      "_aviation_industry_ 3 252\n",
      "_aviation_industry_ 3 253\n",
      "_aviation_industry_ 3 253\n",
      "_aviation_industry_ 3 253\n",
      "_aviation_industry_ 3 254\n",
      "_aviation_industry_ 3 254\n",
      "_aviation_industry_ 3 254\n",
      "_aviation_industry_ 3 255\n",
      "_aviation_industry_ 3 255\n",
      "_aviation_industry_ 3 255\n",
      "_aviation_industry_ 3 256\n",
      "_aviation_industry_ 3 256\n",
      "_aviation_industry_ 3 256\n",
      "_aviation_industry_ 3 257\n",
      "_aviation_industry_ 3 257\n",
      "_aviation_industry_ 3 257\n",
      "_aviation_industry_ 3 258\n",
      "_aviation_industry_ 3 258\n",
      "_aviation_industry_ 3 258\n",
      "_aviation_industry_ 3 259\n",
      "_aviation_industry_ 3 259\n",
      "_aviation_industry_ 3 259\n",
      "_aviation_industry_ 3 260\n",
      "_aviation_industry_ 3 260\n",
      "_aviation_industry_ 3 260\n",
      "_aviation_industry_ 3 261\n",
      "_aviation_industry_ 3 261\n",
      "_aviation_industry_ 3 261\n",
      "_aviation_industry_ 3 262\n",
      "_aviation_industry_ 3 262\n",
      "_aviation_industry_ 3 262\n",
      "_aviation_industry_ 3 263\n",
      "_aviation_industry_ 3 264\n",
      "_aviation_industry_ 3 265\n",
      "_aviation_industry_ 3 266\n",
      "_aviation_industry_ 3 266\n",
      "_aviation_industry_ 3 266\n",
      "_aviation_industry_ 3 267\n",
      "_aviation_industry_ 3 267\n",
      "_aviation_industry_ 3 267\n",
      "_aviation_industry_ 3 268\n",
      "_aviation_industry_ 3 269\n",
      "_aviation_industry_ 3 269\n",
      "_aviation_industry_ 3 269\n",
      "_aviation_industry_ 3 270\n",
      "_aviation_industry_ 3 270\n",
      "_aviation_industry_ 3 270\n",
      "_aviation_industry_ 3 271\n",
      "_aviation_industry_ 3 271\n",
      "_aviation_industry_ 3 271\n",
      "_aviation_industry_ 3 272\n",
      "_aviation_industry_ 3 272\n",
      "_aviation_industry_ 3 272\n",
      "_aviation_industry_ 3 273\n",
      "_aviation_industry_ 3 273\n",
      "_aviation_industry_ 3 273\n",
      "_aviation_industry_ 3 274\n",
      "_aviation_industry_ 3 275\n",
      "_aviation_industry_ 3 275\n",
      "_aviation_industry_ 3 275\n",
      "_aviation_industry_ 3 276\n",
      "_aviation_industry_ 3 276\n",
      "_aviation_industry_ 3 276\n",
      "_aviation_industry_ 3 277\n",
      "_aviation_industry_ 3 277\n",
      "_aviation_industry_ 3 277\n",
      "_aviation_industry_ 3 278\n",
      "_aviation_industry_ 3 278\n",
      "_aviation_industry_ 3 278\n",
      "_aviation_industry_ 3 279\n",
      "_aviation_industry_ 3 279\n",
      "_aviation_industry_ 3 279\n",
      "_aviation_industry_ 3 280\n",
      "_aviation_industry_ 3 280\n",
      "_aviation_industry_ 3 280\n",
      "_aviation_industry_ 3 281\n",
      "_aviation_industry_ 3 281\n",
      "_aviation_industry_ 3 281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_aviation_industry_ 3 282\n",
      "_aviation_industry_ 3 283\n",
      "_aviation_industry_ 3 283\n",
      "_aviation_industry_ 3 283\n",
      "_aviation_industry_ 3 284\n",
      "_aviation_industry_ 3 284\n",
      "_aviation_industry_ 3 284\n",
      "_aviation_industry_ 3 285\n",
      "_aviation_industry_ 3 285\n",
      "_aviation_industry_ 3 285\n",
      "_aviation_industry_ 3 286\n",
      "_aviation_industry_ 3 286\n",
      "_aviation_industry_ 3 286\n",
      "_aviation_industry_ 3 287\n",
      "_aviation_industry_ 3 287\n",
      "_aviation_industry_ 3 287\n",
      "_aviation_industry_ 3 288\n",
      "_aviation_industry_ 3 288\n",
      "_aviation_industry_ 3 288\n",
      "_aviation_industry_ 3 289\n",
      "_aviation_industry_ 3 289\n",
      "_aviation_industry_ 3 289\n",
      "_aviation_industry_ 3 290\n",
      "_aviation_industry_ 3 291\n",
      "_aviation_industry_ 3 292\n",
      "_aviation_industry_ 3 293\n",
      "_aviation_industry_ 3 294\n",
      "_aviation_industry_ 3 294\n",
      "_aviation_industry_ 3 294\n",
      "_aviation_industry_ 3 295\n",
      "_aviation_industry_ 3 295\n",
      "_aviation_industry_ 3 295\n",
      "_aviation_industry_ 3 296\n",
      "_aviation_industry_ 3 296\n",
      "_aviation_industry_ 3 296\n",
      "_aviation_industry_ 3 297\n",
      "_aviation_industry_ 3 298\n",
      "_aviation_industry_ 3 299\n",
      "_aviation_industry_ 3 299\n",
      "_aviation_industry_ 3 299\n",
      "_aviation_industry_ 3 300\n",
      "_aviation_industry_ 3 300\n",
      "_aviation_industry_ 3 300\n",
      "_aviation_industry_ 4 301\n",
      "_aviation_industry_ 4 301\n",
      "_aviation_industry_ 4 301\n",
      "_aviation_industry_ 4 302\n",
      "_aviation_industry_ 4 302\n",
      "_aviation_industry_ 4 302\n",
      "_aviation_industry_ 4 303\n",
      "_aviation_industry_ 4 304\n",
      "_aviation_industry_ 4 304\n",
      "_aviation_industry_ 4 304\n",
      "_aviation_industry_ 4 305\n",
      "_aviation_industry_ 4 305\n",
      "_aviation_industry_ 4 305\n",
      "_aviation_industry_ 4 306\n",
      "_aviation_industry_ 4 306\n",
      "_aviation_industry_ 4 306\n",
      "_aviation_industry_ 4 307\n",
      "_aviation_industry_ 4 307\n",
      "_aviation_industry_ 4 307\n",
      "_aviation_industry_ 4 308\n",
      "_aviation_industry_ 4 308\n",
      "_aviation_industry_ 4 308\n",
      "_aviation_industry_ 4 309\n",
      "_aviation_industry_ 4 309\n",
      "_aviation_industry_ 4 309\n",
      "_aviation_industry_ 4 310\n",
      "_aviation_industry_ 4 311\n",
      "_aviation_industry_ 4 311\n",
      "_aviation_industry_ 4 311\n",
      "_aviation_industry_ 4 312\n",
      "_aviation_industry_ 4 312\n",
      "_aviation_industry_ 4 312\n",
      "_aviation_industry_ 4 313\n",
      "_aviation_industry_ 4 314\n",
      "_aviation_industry_ 4 314\n",
      "_aviation_industry_ 4 314\n",
      "_aviation_industry_ 4 315\n",
      "_aviation_industry_ 4 315\n",
      "_aviation_industry_ 4 315\n",
      "_aviation_industry_ 4 316\n",
      "_aviation_industry_ 4 316\n",
      "_aviation_industry_ 4 316\n",
      "_aviation_industry_ 4 317\n",
      "_aviation_industry_ 4 317\n",
      "_aviation_industry_ 4 317\n",
      "_aviation_industry_ 4 318\n",
      "_aviation_industry_ 4 318\n",
      "_aviation_industry_ 4 318\n",
      "_aviation_industry_ 4 319\n",
      "_aviation_industry_ 4 319\n",
      "_aviation_industry_ 4 319\n",
      "_aviation_industry_ 4 320\n",
      "_aviation_industry_ 4 320\n",
      "_aviation_industry_ 4 320\n",
      "_aviation_industry_ 4 321\n",
      "_aviation_industry_ 4 322\n",
      "_aviation_industry_ 4 323\n",
      "_aviation_industry_ 4 324\n",
      "_aviation_industry_ 4 324\n",
      "_aviation_industry_ 4 324\n",
      "_aviation_industry_ 4 325\n",
      "_aviation_industry_ 4 325\n",
      "_aviation_industry_ 4 325\n",
      "_aviation_industry_ 4 326\n",
      "_aviation_industry_ 4 326\n",
      "_aviation_industry_ 4 326\n",
      "_aviation_industry_ 4 327\n",
      "_aviation_industry_ 4 327\n",
      "_aviation_industry_ 4 327\n",
      "_aviation_industry_ 4 328\n",
      "_aviation_industry_ 4 328\n",
      "_aviation_industry_ 4 328\n",
      "_aviation_industry_ 4 329\n",
      "_aviation_industry_ 4 329\n",
      "_aviation_industry_ 4 329\n",
      "_aviation_industry_ 4 330\n",
      "_aviation_industry_ 4 330\n",
      "_aviation_industry_ 4 330\n",
      "_aviation_industry_ 4 331\n",
      "_aviation_industry_ 4 331\n",
      "_aviation_industry_ 4 331\n",
      "_aviation_industry_ 4 332\n",
      "_aviation_industry_ 4 332\n",
      "_aviation_industry_ 4 332\n",
      "_aviation_industry_ 4 333\n",
      "_aviation_industry_ 4 334\n",
      "_aviation_industry_ 4 335\n",
      "_aviation_industry_ 4 336\n",
      "_aviation_industry_ 4 337\n",
      "_aviation_industry_ 4 337\n",
      "_aviation_industry_ 4 337\n",
      "_aviation_industry_ 4 338\n",
      "_aviation_industry_ 4 338\n",
      "_aviation_industry_ 4 338\n",
      "_aviation_industry_ 4 339\n",
      "_aviation_industry_ 4 339\n",
      "_aviation_industry_ 4 339\n",
      "_aviation_industry_ 4 340\n",
      "_aviation_industry_ 4 340\n",
      "_aviation_industry_ 4 340\n",
      "_aviation_industry_ 4 341\n",
      "_aviation_industry_ 4 342\n",
      "_aviation_industry_ 4 343\n",
      "_aviation_industry_ 4 343\n",
      "_aviation_industry_ 4 343\n",
      "_aviation_industry_ 4 344\n",
      "_aviation_industry_ 4 344\n",
      "_aviation_industry_ 4 344\n",
      "_aviation_industry_ 4 345\n",
      "_aviation_industry_ 4 345\n",
      "_aviation_industry_ 4 345\n",
      "_aviation_industry_ 4 346\n",
      "_aviation_industry_ 4 347\n",
      "_aviation_industry_ 4 347\n",
      "_aviation_industry_ 4 347\n",
      "_aviation_industry_ 4 348\n",
      "_aviation_industry_ 4 348\n",
      "_aviation_industry_ 4 348\n",
      "_aviation_industry_ 4 349\n",
      "_aviation_industry_ 4 349\n",
      "_aviation_industry_ 4 349\n",
      "_aviation_industry_ 4 350\n",
      "_aviation_industry_ 4 350\n",
      "_aviation_industry_ 4 350\n",
      "_aviation_industry_ 4 351\n",
      "_aviation_industry_ 4 352\n",
      "_aviation_industry_ 4 353\n",
      "_aviation_industry_ 4 354\n",
      "_aviation_industry_ 4 354\n",
      "_aviation_industry_ 4 354\n",
      "_aviation_industry_ 4 355\n",
      "_aviation_industry_ 4 355\n",
      "_aviation_industry_ 4 355\n",
      "_aviation_industry_ 4 356\n",
      "_aviation_industry_ 4 356\n",
      "_aviation_industry_ 4 356\n",
      "_aviation_industry_ 4 357\n",
      "_aviation_industry_ 4 357\n",
      "_aviation_industry_ 4 357\n",
      "_aviation_industry_ 4 358\n",
      "_aviation_industry_ 4 358\n",
      "_aviation_industry_ 4 358\n",
      "_aviation_industry_ 4 359\n",
      "_aviation_industry_ 4 359\n",
      "_aviation_industry_ 4 359\n",
      "_aviation_industry_ 4 360\n",
      "_aviation_industry_ 4 360\n",
      "_aviation_industry_ 4 360\n",
      "_aviation_industry_ 4 361\n",
      "_aviation_industry_ 4 362\n",
      "_aviation_industry_ 4 362\n",
      "_aviation_industry_ 4 362\n",
      "_aviation_industry_ 4 363\n",
      "_aviation_industry_ 4 363\n",
      "_aviation_industry_ 4 363\n",
      "_aviation_industry_ 4 364\n",
      "_aviation_industry_ 4 364\n",
      "_aviation_industry_ 4 364\n",
      "_aviation_industry_ 4 365\n",
      "_aviation_industry_ 4 365\n",
      "_aviation_industry_ 4 365\n",
      "_aviation_industry_ 4 366\n",
      "_aviation_industry_ 4 367\n",
      "_aviation_industry_ 4 367\n",
      "_aviation_industry_ 4 367\n",
      "_aviation_industry_ 4 368\n",
      "_aviation_industry_ 4 368\n",
      "_aviation_industry_ 4 368\n",
      "_aviation_industry_ 4 369\n",
      "_aviation_industry_ 4 369\n",
      "_aviation_industry_ 4 369\n",
      "_aviation_industry_ 4 370\n",
      "_aviation_industry_ 4 370\n",
      "_aviation_industry_ 4 370\n",
      "_aviation_industry_ 4 371\n",
      "_aviation_industry_ 4 371\n",
      "_aviation_industry_ 4 371\n",
      "_aviation_industry_ 4 372\n",
      "_aviation_industry_ 4 372\n",
      "_aviation_industry_ 4 372\n",
      "_aviation_industry_ 4 373\n",
      "_aviation_industry_ 4 373\n",
      "_aviation_industry_ 4 373\n",
      "_aviation_industry_ 4 374\n",
      "_aviation_industry_ 4 375\n",
      "_aviation_industry_ 4 375\n",
      "_aviation_industry_ 4 375\n",
      "_aviation_industry_ 4 376\n",
      "_aviation_industry_ 4 376\n",
      "_aviation_industry_ 4 376\n",
      "_aviation_industry_ 4 377\n",
      "_aviation_industry_ 4 378\n",
      "_aviation_industry_ 4 378\n",
      "_aviation_industry_ 4 378\n",
      "_aviation_industry_ 4 379\n",
      "_aviation_industry_ 4 379\n",
      "_aviation_industry_ 4 379\n",
      "_aviation_industry_ 4 380\n",
      "_aviation_industry_ 4 380\n",
      "_aviation_industry_ 4 380\n",
      "_aviation_industry_ 4 381\n",
      "_aviation_industry_ 4 381\n",
      "_aviation_industry_ 4 381\n",
      "_aviation_industry_ 4 382\n",
      "_aviation_industry_ 4 382\n",
      "_aviation_industry_ 4 382\n",
      "_aviation_industry_ 4 383\n",
      "_aviation_industry_ 4 384\n",
      "_aviation_industry_ 4 385\n",
      "_aviation_industry_ 4 386\n",
      "_aviation_industry_ 4 386\n",
      "_aviation_industry_ 4 386\n",
      "_aviation_industry_ 4 387\n",
      "_aviation_industry_ 4 387\n",
      "_aviation_industry_ 4 387\n",
      "_aviation_industry_ 4 388\n",
      "_aviation_industry_ 4 389\n",
      "_aviation_industry_ 4 390\n",
      "_aviation_industry_ 4 390\n",
      "_aviation_industry_ 4 390\n",
      "_aviation_industry_ 4 391\n",
      "_aviation_industry_ 4 392\n",
      "_aviation_industry_ 4 392\n",
      "_aviation_industry_ 4 392\n",
      "_aviation_industry_ 4 393\n",
      "_aviation_industry_ 4 393\n",
      "_aviation_industry_ 4 393\n",
      "_aviation_industry_ 4 394\n",
      "_aviation_industry_ 4 395\n",
      "_aviation_industry_ 4 395\n",
      "_aviation_industry_ 4 395\n",
      "_aviation_industry_ 4 396\n",
      "_aviation_industry_ 4 396\n",
      "_aviation_industry_ 4 396\n",
      "_aviation_industry_ 4 397\n",
      "_aviation_industry_ 4 398\n",
      "_aviation_industry_ 4 398\n",
      "_aviation_industry_ 4 398\n",
      "_aviation_industry_ 4 399\n",
      "_aviation_industry_ 4 399\n",
      "_aviation_industry_ 4 399\n",
      "_aviation_industry_ 4 400\n",
      "_aviation_industry_ 4 400\n",
      "_aviation_industry_ 4 400\n",
      "_aviation_industry_ 5 401\n",
      "_aviation_industry_ 5 402\n",
      "_aviation_industry_ 5 402\n",
      "_aviation_industry_ 5 402\n",
      "_aviation_industry_ 5 403\n",
      "_aviation_industry_ 5 403\n",
      "_aviation_industry_ 5 403\n",
      "_aviation_industry_ 5 404\n",
      "_aviation_industry_ 5 404\n",
      "_aviation_industry_ 5 404\n",
      "_aviation_industry_ 5 405\n",
      "_aviation_industry_ 5 406\n",
      "_aviation_industry_ 5 407\n",
      "_aviation_industry_ 5 407\n",
      "_aviation_industry_ 5 407\n",
      "_aviation_industry_ 5 408\n",
      "_aviation_industry_ 5 409\n",
      "_aviation_industry_ 5 410\n",
      "_aviation_industry_ 5 410\n",
      "_aviation_industry_ 5 410\n",
      "_aviation_industry_ 5 411\n",
      "_aviation_industry_ 5 412\n",
      "_aviation_industry_ 5 413\n",
      "_aviation_industry_ 5 413\n",
      "_aviation_industry_ 5 413\n",
      "_aviation_industry_ 5 414\n",
      "_aviation_industry_ 5 414\n",
      "_aviation_industry_ 5 414\n",
      "_aviation_industry_ 5 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_aviation_industry_ 5 416\n",
      "_aviation_industry_ 5 416\n",
      "_aviation_industry_ 5 416\n",
      "_aviation_industry_ 5 417\n",
      "_aviation_industry_ 5 417\n",
      "_aviation_industry_ 5 417\n",
      "_aviation_industry_ 5 418\n",
      "_aviation_industry_ 5 418\n",
      "_aviation_industry_ 5 418\n",
      "_aviation_industry_ 5 419\n",
      "_aviation_industry_ 5 419\n",
      "_aviation_industry_ 5 419\n",
      "_aviation_industry_ 5 420\n",
      "_aviation_industry_ 5 420\n",
      "_aviation_industry_ 5 420\n",
      "_aviation_industry_ 5 421\n",
      "_aviation_industry_ 5 421\n",
      "_aviation_industry_ 5 421\n",
      "_aviation_industry_ 5 422\n",
      "_aviation_industry_ 5 422\n",
      "_aviation_industry_ 5 422\n",
      "_aviation_industry_ 5 423\n",
      "_aviation_industry_ 5 423\n",
      "_aviation_industry_ 5 423\n",
      "_aviation_industry_ 5 424\n",
      "_aviation_industry_ 5 424\n",
      "_aviation_industry_ 5 424\n",
      "_aviation_industry_ 5 425\n",
      "_aviation_industry_ 5 425\n",
      "_aviation_industry_ 5 425\n",
      "_aviation_industry_ 5 426\n",
      "_aviation_industry_ 5 426\n",
      "_aviation_industry_ 5 426\n",
      "_aviation_industry_ 5 427\n",
      "_aviation_industry_ 5 428\n",
      "_aviation_industry_ 5 429\n",
      "_aviation_industry_ 5 430\n",
      "_aviation_industry_ 5 430\n",
      "_aviation_industry_ 5 430\n",
      "_aviation_industry_ 5 431\n",
      "_aviation_industry_ 5 432\n",
      "_aviation_industry_ 5 433\n",
      "_aviation_industry_ 5 433\n",
      "_aviation_industry_ 5 433\n",
      "_aviation_industry_ 5 434\n",
      "_aviation_industry_ 5 434\n",
      "_aviation_industry_ 5 434\n",
      "_aviation_industry_ 5 435\n",
      "_aviation_industry_ 5 436\n",
      "_aviation_industry_ 5 436\n",
      "_aviation_industry_ 5 436\n",
      "_aviation_industry_ 5 437\n",
      "_aviation_industry_ 5 438\n",
      "_aviation_industry_ 5 439\n",
      "_aviation_industry_ 5 440\n",
      "_aviation_industry_ 5 441\n",
      "_aviation_industry_ 5 441\n",
      "_aviation_industry_ 5 441\n",
      "_aviation_industry_ 5 442\n",
      "_aviation_industry_ 5 442\n",
      "_aviation_industry_ 5 442\n",
      "_aviation_industry_ 5 443\n",
      "_aviation_industry_ 5 443\n",
      "_aviation_industry_ 5 443\n",
      "_aviation_industry_ 5 444\n",
      "_aviation_industry_ 5 444\n",
      "_aviation_industry_ 5 444\n",
      "_aviation_industry_ 5 445\n",
      "_aviation_industry_ 5 445\n",
      "_aviation_industry_ 5 445\n",
      "_aviation_industry_ 5 446\n",
      "_aviation_industry_ 5 446\n",
      "_aviation_industry_ 5 446\n",
      "_aviation_industry_ 5 447\n",
      "_aviation_industry_ 5 447\n",
      "_aviation_industry_ 5 447\n",
      "_aviation_industry_ 5 448\n",
      "_aviation_industry_ 5 449\n",
      "_aviation_industry_ 5 449\n",
      "_aviation_industry_ 5 449\n",
      "_aviation_industry_ 5 450\n",
      "_aviation_industry_ 5 450\n",
      "_aviation_industry_ 5 450\n",
      "_aviation_industry_ 5 451\n",
      "_aviation_industry_ 5 451\n",
      "_aviation_industry_ 5 451\n",
      "_aviation_industry_ 5 452\n",
      "_aviation_industry_ 5 452\n",
      "_aviation_industry_ 5 452\n",
      "_aviation_industry_ 5 453\n",
      "_aviation_industry_ 5 453\n",
      "_aviation_industry_ 5 453\n",
      "_aviation_industry_ 5 454\n",
      "_aviation_industry_ 5 454\n",
      "_aviation_industry_ 5 454\n",
      "_aviation_industry_ 5 455\n",
      "_aviation_industry_ 5 456\n",
      "_aviation_industry_ 5 457\n",
      "_aviation_industry_ 5 458\n",
      "_aviation_industry_ 5 459\n",
      "_aviation_industry_ 5 460\n",
      "_aviation_industry_ 5 461\n",
      "_aviation_industry_ 5 461\n",
      "_aviation_industry_ 5 461\n",
      "_aviation_industry_ 5 462\n",
      "_aviation_industry_ 5 462\n",
      "_aviation_industry_ 5 462\n",
      "_aviation_industry_ 5 463\n",
      "_aviation_industry_ 5 463\n",
      "_aviation_industry_ 5 463\n",
      "_aviation_industry_ 5 464\n",
      "_aviation_industry_ 5 464\n",
      "_aviation_industry_ 5 464\n",
      "_aviation_industry_ 5 465\n",
      "_aviation_industry_ 5 466\n",
      "_aviation_industry_ 5 466\n",
      "_aviation_industry_ 5 466\n",
      "_aviation_industry_ 5 467\n",
      "_aviation_industry_ 5 468\n",
      "_aviation_industry_ 5 469\n",
      "_aviation_industry_ 5 470\n",
      "_aviation_industry_ 5 470\n",
      "_aviation_industry_ 5 470\n",
      "_aviation_industry_ 5 471\n",
      "_aviation_industry_ 5 471\n",
      "_aviation_industry_ 5 471\n",
      "_aviation_industry_ 5 472\n",
      "_aviation_industry_ 5 472\n",
      "_aviation_industry_ 5 472\n",
      "_aviation_industry_ 5 473\n",
      "_aviation_industry_ 5 473\n",
      "_aviation_industry_ 5 473\n",
      "_aviation_industry_ 5 474\n",
      "_aviation_industry_ 5 474\n",
      "_aviation_industry_ 5 474\n",
      "_aviation_industry_ 5 475\n",
      "_aviation_industry_ 5 475\n",
      "_aviation_industry_ 5 475\n",
      "_aviation_industry_ 5 476\n",
      "_aviation_industry_ 5 476\n",
      "_aviation_industry_ 5 476\n",
      "_aviation_industry_ 5 477\n",
      "_aviation_industry_ 5 478\n",
      "_aviation_industry_ 5 478\n",
      "_aviation_industry_ 5 478\n",
      "_aviation_industry_ 5 479\n",
      "_aviation_industry_ 5 479\n",
      "_aviation_industry_ 5 479\n",
      "_aviation_industry_ 5 480\n",
      "_aviation_industry_ 5 480\n",
      "_aviation_industry_ 5 480\n",
      "_aviation_industry_ 5 481\n",
      "_aviation_industry_ 5 481\n",
      "_aviation_industry_ 5 481\n",
      "_aviation_industry_ 5 482\n",
      "_aviation_industry_ 5 482\n",
      "_aviation_industry_ 5 482\n",
      "_aviation_industry_ 5 483\n",
      "_aviation_industry_ 5 484\n",
      "_aviation_industry_ 5 485\n",
      "_aviation_industry_ 5 485\n",
      "_aviation_industry_ 5 485\n",
      "_aviation_industry_ 5 486\n",
      "_aviation_industry_ 5 486\n",
      "_aviation_industry_ 5 486\n",
      "_aviation_industry_ 5 487\n",
      "_aviation_industry_ 5 488\n",
      "_aviation_industry_ 5 488\n",
      "_aviation_industry_ 5 488\n",
      "_aviation_industry_ 5 489\n",
      "_aviation_industry_ 5 489\n",
      "_aviation_industry_ 5 489\n",
      "_aviation_industry_ 5 490\n",
      "_aviation_industry_ 5 491\n",
      "_aviation_industry_ 5 492\n",
      "_aviation_industry_ 5 493\n",
      "_aviation_industry_ 5 494\n",
      "_aviation_industry_ 5 495\n",
      "_aviation_industry_ 5 496\n",
      "_aviation_industry_ 5 496\n",
      "_aviation_industry_ 5 496\n",
      "_aviation_industry_ 5 497\n",
      "_aviation_industry_ 5 497\n",
      "_aviation_industry_ 5 497\n",
      "_aviation_industry_ 5 498\n",
      "_aviation_industry_ 5 498\n",
      "_aviation_industry_ 5 498\n",
      "_aviation_industry_ 5 499\n",
      "_aviation_industry_ 5 500\n",
      "_aviation_industry_ 6 501\n",
      "_aviation_industry_ 6 502\n",
      "_aviation_industry_ 6 503\n",
      "_aviation_industry_ 6 504\n",
      "_aviation_industry_ 6 504\n",
      "_aviation_industry_ 6 504\n",
      "_aviation_industry_ 6 505\n",
      "_aviation_industry_ 6 505\n",
      "_aviation_industry_ 6 505\n",
      "_aviation_industry_ 6 506\n",
      "_aviation_industry_ 6 506\n",
      "_aviation_industry_ 6 506\n",
      "_aviation_industry_ 6 507\n",
      "_aviation_industry_ 6 508\n",
      "_aviation_industry_ 6 508\n",
      "_aviation_industry_ 6 508\n",
      "_aviation_industry_ 6 509\n",
      "_aviation_industry_ 6 510\n",
      "_aviation_industry_ 6 511\n",
      "_aviation_industry_ 6 511\n",
      "_aviation_industry_ 6 511\n",
      "_aviation_industry_ 6 512\n",
      "_aviation_industry_ 6 513\n",
      "_aviation_industry_ 6 513\n",
      "_aviation_industry_ 6 513\n",
      "_aviation_industry_ 6 514\n",
      "_aviation_industry_ 6 514\n",
      "_aviation_industry_ 6 514\n",
      "_aviation_industry_ 6 515\n",
      "_aviation_industry_ 6 515\n",
      "_aviation_industry_ 6 515\n",
      "_aviation_industry_ 6 516\n",
      "_aviation_industry_ 6 517\n",
      "_aviation_industry_ 6 517\n",
      "_aviation_industry_ 6 517\n",
      "_aviation_industry_ 6 518\n",
      "_aviation_industry_ 6 518\n",
      "_aviation_industry_ 6 518\n",
      "_aviation_industry_ 6 519\n",
      "_aviation_industry_ 6 519\n",
      "_aviation_industry_ 6 519\n",
      "_aviation_industry_ 6 520\n",
      "_aviation_industry_ 6 521\n",
      "_aviation_industry_ 6 522\n",
      "_aviation_industry_ 6 522\n",
      "_aviation_industry_ 6 522\n",
      "_aviation_industry_ 6 523\n",
      "_aviation_industry_ 6 523\n",
      "_aviation_industry_ 6 523\n",
      "_aviation_industry_ 6 524\n",
      "_aviation_industry_ 6 524\n",
      "_aviation_industry_ 6 524\n",
      "_aviation_industry_ 6 525\n",
      "_aviation_industry_ 6 525\n",
      "_aviation_industry_ 6 525\n",
      "_aviation_industry_ 6 526\n",
      "_aviation_industry_ 6 526\n",
      "_aviation_industry_ 6 526\n",
      "_aviation_industry_ 6 527\n",
      "_aviation_industry_ 6 527\n",
      "_aviation_industry_ 6 527\n",
      "_aviation_industry_ 6 528\n",
      "_aviation_industry_ 6 528\n",
      "_aviation_industry_ 6 528\n",
      "_aviation_industry_ 6 529\n",
      "_aviation_industry_ 6 529\n",
      "_aviation_industry_ 6 529\n",
      "_aviation_industry_ 6 530\n",
      "_aviation_industry_ 6 531\n",
      "_aviation_industry_ 6 531\n",
      "_aviation_industry_ 6 531\n",
      "_aviation_industry_ 6 532\n",
      "_aviation_industry_ 6 532\n",
      "_aviation_industry_ 6 532\n",
      "_aviation_industry_ 6 533\n",
      "_aviation_industry_ 6 533\n",
      "_aviation_industry_ 6 533\n",
      "_aviation_industry_ 6 534\n",
      "_aviation_industry_ 6 535\n",
      "_aviation_industry_ 6 535\n",
      "_aviation_industry_ 6 535\n",
      "_aviation_industry_ 6 536\n",
      "_aviation_industry_ 6 536\n",
      "_aviation_industry_ 6 536\n",
      "_aviation_industry_ 6 537\n",
      "_aviation_industry_ 6 537\n",
      "_aviation_industry_ 6 537\n",
      "_aviation_industry_ 6 538\n",
      "_aviation_industry_ 6 538\n",
      "_aviation_industry_ 6 538\n",
      "_aviation_industry_ 6 539\n",
      "_aviation_industry_ 6 540\n",
      "_aviation_industry_ 6 541\n",
      "_aviation_industry_ 6 541\n",
      "_aviation_industry_ 6 541\n",
      "_aviation_industry_ 6 542\n",
      "_aviation_industry_ 6 542\n",
      "_aviation_industry_ 6 542\n",
      "_aviation_industry_ 6 543\n",
      "_aviation_industry_ 6 543\n",
      "_aviation_industry_ 6 543\n",
      "_aviation_industry_ 6 544\n",
      "_aviation_industry_ 6 544\n",
      "_aviation_industry_ 6 544\n",
      "_aviation_industry_ 6 545\n",
      "_aviation_industry_ 6 545\n",
      "_aviation_industry_ 6 545\n",
      "_aviation_industry_ 6 546\n",
      "_aviation_industry_ 6 546\n",
      "_aviation_industry_ 6 546\n",
      "_aviation_industry_ 6 547\n",
      "_aviation_industry_ 6 547\n",
      "_aviation_industry_ 6 547\n",
      "_aviation_industry_ 6 548\n",
      "_aviation_industry_ 6 549\n",
      "_aviation_industry_ 6 550\n",
      "_aviation_industry_ 6 550\n",
      "_aviation_industry_ 6 550\n",
      "_aviation_industry_ 6 551\n",
      "_aviation_industry_ 6 551\n",
      "_aviation_industry_ 6 551\n",
      "_aviation_industry_ 6 552\n",
      "_aviation_industry_ 6 552\n",
      "_aviation_industry_ 6 552\n",
      "_aviation_industry_ 6 553\n",
      "_aviation_industry_ 6 553\n",
      "_aviation_industry_ 6 553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_aviation_industry_ 6 554\n",
      "_aviation_industry_ 6 554\n",
      "_aviation_industry_ 6 554\n",
      "_aviation_industry_ 6 555\n",
      "_aviation_industry_ 6 555\n",
      "_aviation_industry_ 6 555\n",
      "_aviation_industry_ 6 556\n",
      "_aviation_industry_ 6 556\n",
      "_aviation_industry_ 6 556\n",
      "_aviation_industry_ 6 557\n",
      "_aviation_industry_ 6 557\n",
      "_aviation_industry_ 6 557\n",
      "_aviation_industry_ 6 558\n",
      "_aviation_industry_ 6 558\n",
      "_aviation_industry_ 6 558\n",
      "_aviation_industry_ 6 559\n",
      "_aviation_industry_ 6 559\n",
      "_aviation_industry_ 6 559\n",
      "_aviation_industry_ 6 560\n",
      "_aviation_industry_ 6 560\n",
      "_aviation_industry_ 6 560\n",
      "_aviation_industry_ 6 561\n",
      "_aviation_industry_ 6 562\n",
      "_aviation_industry_ 6 563\n",
      "_aviation_industry_ 6 563\n",
      "_aviation_industry_ 6 563\n",
      "_aviation_industry_ 6 564\n",
      "_aviation_industry_ 6 564\n",
      "_aviation_industry_ 6 564\n",
      "_aviation_industry_ 6 565\n",
      "_aviation_industry_ 6 565\n",
      "_aviation_industry_ 6 565\n",
      "_aviation_industry_ 6 566\n",
      "_aviation_industry_ 6 567\n",
      "_aviation_industry_ 6 568\n",
      "_aviation_industry_ 6 569\n",
      "_aviation_industry_ 6 569\n",
      "_aviation_industry_ 6 569\n",
      "_aviation_industry_ 6 570\n",
      "_aviation_industry_ 6 571\n",
      "_aviation_industry_ 6 572\n",
      "_aviation_industry_ 6 572\n",
      "_aviation_industry_ 6 572\n",
      "_aviation_industry_ 6 573\n",
      "_aviation_industry_ 6 573\n",
      "_aviation_industry_ 6 573\n",
      "_aviation_industry_ 6 574\n",
      "_aviation_industry_ 6 575\n",
      "_aviation_industry_ 6 576\n",
      "_aviation_industry_ 6 577\n",
      "_aviation_industry_ 6 578\n",
      "_aviation_industry_ 6 578\n",
      "_aviation_industry_ 6 578\n",
      "_aviation_industry_ 6 579\n",
      "_aviation_industry_ 6 580\n",
      "_aviation_industry_ 6 581\n",
      "_aviation_industry_ 6 581\n",
      "_aviation_industry_ 6 581\n",
      "_aviation_industry_ 6 582\n",
      "_aviation_industry_ 6 583\n",
      "_aviation_industry_ 6 583\n",
      "_aviation_industry_ 6 583\n",
      "_aviation_industry_ 6 584\n",
      "_aviation_industry_ 6 584\n",
      "_aviation_industry_ 6 584\n",
      "_aviation_industry_ 6 585\n",
      "_aviation_industry_ 6 585\n",
      "_aviation_industry_ 6 585\n",
      "_aviation_industry_ 6 586\n",
      "_aviation_industry_ 6 587\n",
      "_aviation_industry_ 6 587\n",
      "_aviation_industry_ 6 587\n",
      "_aviation_industry_ 6 588\n",
      "_aviation_industry_ 6 588\n",
      "_aviation_industry_ 6 588\n",
      "_aviation_industry_ 6 589\n",
      "_aviation_industry_ 6 590\n",
      "_aviation_industry_ 6 591\n",
      "_aviation_industry_ 6 591\n",
      "_aviation_industry_ 6 591\n",
      "_aviation_industry_ 6 592\n",
      "_aviation_industry_ 6 592\n",
      "_aviation_industry_ 6 592\n",
      "_aviation_industry_ 6 593\n",
      "_aviation_industry_ 6 593\n",
      "_aviation_industry_ 6 593\n",
      "_aviation_industry_ 6 594\n",
      "_aviation_industry_ 6 594\n",
      "_aviation_industry_ 6 594\n",
      "_aviation_industry_ 6 595\n",
      "_aviation_industry_ 6 595\n",
      "_aviation_industry_ 6 595\n",
      "_aviation_industry_ 6 596\n",
      "_aviation_industry_ 6 596\n",
      "_aviation_industry_ 6 596\n",
      "_aviation_industry_ 6 597\n",
      "_aviation_industry_ 6 597\n",
      "_aviation_industry_ 6 597\n",
      "_aviation_industry_ 6 598\n",
      "_aviation_industry_ 6 598\n",
      "_aviation_industry_ 6 598\n",
      "_aviation_industry_ 6 599\n",
      "_aviation_industry_ 6 599\n",
      "_aviation_industry_ 6 599\n",
      "_aviation_industry_ 6 600\n",
      "_aviation_industry_ 6 600\n",
      "_aviation_industry_ 6 600\n"
     ]
    }
   ],
   "source": [
    "topics=[(\"_green_utilities_\",\"https://www.prnewswire.com/news-releases/environment-latest-news/green-technology-list/?page=\"),(\"_aviation_industry_\",\"https://www.prnewswire.com/news-releases/automotive-transportation-latest-news/airlines-aviation-list/?page=\")]\n",
    "for topic in topics:\n",
    "    bout_going={}\n",
    "    remover=[]\n",
    "    count=1\n",
    "    paged = topic[1]\n",
    "    check_count_n1 = bout_going\n",
    "    for i in range(1,7):\n",
    "        page=paged+str(i)+\"&pagesize=100\"\n",
    "        spec_page= \" \".join(requests.get(page,headers=headers).text.split(\"\\n\"))\n",
    "        #print(spec_page)\n",
    "        soup = BeautifulSoup(spec_page, 'lxml')\n",
    "        [tagstring.extract() for tagstring in soup('a', class_=\"imageLinkWrapper\")]\n",
    "        [tagstring.extract() for tagstring in soup('script')] ### extracts all content not between balance <script> tags\n",
    "        [tagstring.extract() for tagstring in soup('table')] ### extracts all content not between balance <table> tags\n",
    "        [tagstring.extract() for tagstring in soup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "        [tagstring.extract() for tagstring in soup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "        [tagstring.extract() for tagstring in soup('ol')] ### extracts all content not between balance <ol> tags\n",
    "        [tagstring.extract() for tagstring in soup('ul')] ### extracts all content not between balance <ul> tags\n",
    "        #[tagstring.extract() for tagstring in soup('h1')] ### extracts all content not between balance <h1> tags\n",
    "        #[tagstring.extract() for tagstring in soup('h2')] ### extracts all content not between balance <h2> tags\n",
    "       # [tagstring.extract() for tagstring in soup('h3')] ### extracts all content not between balance <h3> tags\n",
    "        #[tagstring.extract() for tagstring in soup('h4')] ### extracts all content not between balance <h4> tags\n",
    "        [tagstring.extract() for tagstring in soup('h5')] ### extracts all content not between balance <h5> tags\n",
    "        [tagstring.extract() for tagstring in soup('img')] ### extracts all content not between balance <img> tags\n",
    "\n",
    "        filtered_content = soup.find_all('div', class_=\"card\")\n",
    "        #print(filtered_content)\n",
    "\n",
    "        for stuff in filtered_content:\n",
    "#             try:\n",
    "            if not stuff:\n",
    "                continue\n",
    "            #print(str(stuff))\n",
    "            url = stuff.find('a', href=True)\n",
    "            url = \"https://www.prnewswire.com\"+re.search(r\"href=\\\"(.*?)\\\"\",str(url),re.DOTALL)[1]\n",
    "            #print(url)\n",
    "#             except:\n",
    "#                 continue            \n",
    "            \n",
    "\n",
    "            title = \"\"\n",
    "            description = \"\"\n",
    "\n",
    "            bout_going[url] = {\"title\":title, \"description\":description, \"keywords\":[],  \"content\":\"\"}\n",
    "            #print(bout_going[url])\n",
    "            spage=requests.get(url,headers=headers).text\n",
    "            #print(spage)\n",
    "            newsoup = BeautifulSoup(spage, 'lxml') \n",
    "            keywords=[]\n",
    "            [tagstring.extract() for tagstring in newsoup('span', class_='tweet_quote')]\n",
    "            [tagstring.extract() for tagstring in newsoup('style')] \n",
    "            [tagstring.extract() for tagstring in newsoup('script')] ### extracts all content not between balance <script> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('table')] ### extracts all content not between balance <table> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('ol')] ### extracts all content not between balance <ol> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('ul')] ### extracts all content not between balance <ul> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h1')] ### extracts all content not between balance <h1> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h2')] ### extracts all content not between balance <h2> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h3')] ### extracts all content not between balance <h3> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h4')] ### extracts all content not between balance <h4> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h5')] ### extracts all content not between balance <h5> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('img')] ### extracts all content not between balance <img> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('br')] ### extracts all content not between balance <img> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('figure')] ### extracts all content not between balance <img> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('h4')] ### extracts all content not between balance <h4> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('p', class_=\"meta text-uppercase mb-s\")] ### extracts all content not between balance <h5> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('p', class_=\"meta\")] ### extracts all content not between balance <img> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('p', class_=\"text-muted\")] ### extracts all content not between balance <img> tags\n",
    "            [tagstring.extract() for tagstring in newsoup('p', class_=\"mb-no\")] \n",
    "            [tagstring.extract() for tagstring in newsoup('span', class_=\"xn-chron\")] \n",
    "            [tagstring.extract() for tagstring in newsoup('span', class_=\"xn-location\")] \n",
    "\n",
    "            filtered_content = newsoup.find_all('p')\n",
    "            content = \"\"\n",
    "            for wrapped_paragraph in filtered_content:\n",
    "                content+= str(wrapped_paragraph.wrap) +\" \"\n",
    "            \n",
    "            content = \" \".join(html.unescape(re.sub(r\"\\s+\",\" \",content,re.DOTALL).strip()).split(\"\\n\"))\n",
    "            #print(content)\n",
    "            bout_going[url][\"content\"]= \" \".join(re.findall(r\"<p.*?>(.*?)</p>\",re.sub(\"<bound\\smethod.*?>>?\",\"\",\" \".join(content.split(\"\\n\")),re.DOTALL).replace(\">>\",\">\"),re.DOTALL))\n",
    "            #print(content)\n",
    "            if len(content)<200:\n",
    "                remover.append(url)\n",
    "                continue\n",
    "            title= re.search(r\"<title>([^<>]+?)</title>\",spage,re.DOTALL)\n",
    "            if title:\n",
    "                bout_going[url][\"title\"]=title[1]\n",
    "            keyword=re.search(r\"temprop=\\\"keywords\\\"\\sname=\\\"keywords\\\"\\scontent=\\\"(.*?)\\\"\",spage,re.DOTALL)\n",
    "            if keyword:\n",
    "                bout_going[url][\"keywords\"]=[word.lower().strip() for word in keyword[1].split(\",\")]\n",
    "            decrip = re.search(r\"itemprop=\\\"description\\\"\\sname=\\\"description\\\"\\scontent=\\\"(.*?)\\\"\",spage,re.DOTALL)\n",
    "            if decrip:\n",
    "                bout_going[url][\"description\"]=html.unescape(decrip[1].strip())\n",
    "            bout_going[url][\"keywords\"]= list(set(keywords))\n",
    "            print(topic[0],i,len(bout_going))\n",
    "        if len(bout_going)== len(check_count_n1):\n",
    "            continue\n",
    "        if len(bout_going[i][\"content\"]) < 100:\n",
    "            remove.append(i)\n",
    "\n",
    "    for i in remover:\n",
    "        try:\n",
    "            bout_going.pop(i)\n",
    "        except:\n",
    "            continue\n",
    "    with open(\"prnewswire.com\"+topic[0]+str(len(bout_going))+\".json\",\"w\") as file:\n",
    "        json.dump(bout_going,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WcNLXfgK3gcU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Krm7J7Xr3gcW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5zDTjPE3gcY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "tv_and_movies_taxonomy_scrape.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
